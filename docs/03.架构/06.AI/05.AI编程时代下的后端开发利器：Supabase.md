---
title: AI编程时代下的后端开发利器：Supabase
date: 2025-09-17 10:45:00
permalink: /pages/supabase-ai-backend/
categories:
  - 架构
  - AI
tags:
  - Supabase
  - AI编程
author:
  name: 轩辕李
  link: https://github.com/xuanyuanli
---

本文聚焦“AI 编程时代”的应用后端诉求，用 Supabase 作为一体化方案的核心支点，从架构到工程落地给出可复用的实践框架与清单。

<!-- more -->

## 一、引言：AI 编程时代的后端新诉求

随着 ChatGPT、Claude、GitHub Copilot 等 `AI 编程工具`的普及，软件开发的节奏和模式正在发生根本性转变。开发者们可以在几分钟内生成完整的功能模块，快速验证产品想法，这种"敏捷至上"的开发模式对后端架构提出了全新的诉求：

### 1、极速原型验证
传统的后端搭建往往需要几天甚至几周，而在 AI 编程时代，产品经理可能在午餐时间就想出了三个不同的产品方向。后端架构必须支持`小时级`的 MVP 搭建，让想法能够快速落地验证。

### 2、向量检索能力成为刚需
几乎所有的 AI 应用都离不开 `RAG`（检索增强生成）模式：
- **知识库问答**：用户上传文档，AI 基于文档内容回答问题
- **代码助手**：检索相关代码片段，提供上下文感知的建议
- **个性化推荐**：基于用户行为向量，推荐相关内容

这意味着向量数据库不再是"可选项"，而是与关系数据库同等重要的基础设施。

### 3、流式处理与实时交互
用户对 AI 应用的体验期望已经被 ChatGPT 重新定义：
- **逐字流式输出**：看到 AI "思考"的过程，而非等待最终结果
- **实时协作**：多用户同时编辑文档、代码，AI 实时提供建议
- **状态同步**：对话历史、处理进度在多设备间无缝同步

### 4、弹性计费与配额管理
AI 推理的成本波动巨大，从 GPT-4 的每千 token $0.03，到本地模型的近乎免费。应用需要：
- **精确的用量追踪**：按 token、按请求、按用户精细计费
- **灵活的配额策略**：免费额度、订阅套餐、按量付费的混合模式
- **成本控制**：防止恶意调用导致的费用爆炸

### 5、多租户安全隔离
AI 应用往往处理敏感的用户数据（文档、对话记录、代码片段），需要严格的数据隔离：
- **企业级多租户**：不同组织的数据绝对隔离
- **细粒度权限控制**：项目级、用户级的数据访问控制
- **审计与合规**：数据访问日志、删除记录的完整追踪

这些新诉求对传统的后端技术栈提出了挑战：你需要同时精通 PostgreSQL、Redis、Elasticsearch、消息队列、身份认证等多个组件，还要考虑它们之间的集成与运维复杂度。而 `Supabase` 作为一个"后端即服务"平台，恰好在这个时间点提供了一个整合的解决方案。

## 二、为什么选择 Supabase（AI 场景优势与边界）

在众多后端方案中，`Supabase` 为 AI 应用提供了独特的价值主张。让我们从技术架构和业务场景两个维度来分析其适用性。

### 1、核心优势：AI 时代的完美契合

#### 1.1、PostgreSQL + pgvector：原生向量支持
不同于 Pinecone、Weaviate 等专用向量数据库，Supabase 基于 `PostgreSQL` + `pgvector` 扩展，提供了独特的优势：

**事务一致性**：向量数据与业务数据在同一个事务中处理
```sql
BEGIN;
-- 插入文档元数据
INSERT INTO documents (title, content, user_id)
VALUES ('AI编程指南', '...', 'user123') RETURNING id;

-- 插入对应的向量数据
INSERT INTO embeddings (document_id, vector)
VALUES (currval('documents_id_seq'), '[0.1, 0.2, ...]');
COMMIT;
```

**关联查询能力**：向量检索可以与业务逻辑无缝结合
```sql
-- 在用户权限范围内进行向量检索
SELECT d.title, d.content, 1 - (e.vector <=> query_vector) as similarity
FROM documents d
JOIN embeddings e ON d.id = e.document_id
JOIN user_permissions p ON d.org_id = p.org_id
WHERE p.user_id = auth.uid()
ORDER BY e.vector <=> query_vector
LIMIT 10;
```

**丰富的索引策略**：
- `ivfflat`：适合中等规模（< 100万向量），查询速度快
- `hnsw`：适合大规模数据，内存友好，支持并发查询

#### 1.2、一体化架构：减少集成地狱
传统方案往往需要组合多个服务：
```
Firebase Auth + AWS S3 + Pinecone + Redis + Express.js + WebSocket...
```

Supabase 将这些能力整合在一个平台：
- **Auth**：JWT + Row Level Security，原生多租户支持
- **Storage**：文件上传 + CDN + 权限控制
- **Database**：PostgreSQL + 实时订阅
- **Edge Functions**：AI 推理网关 + 流式处理
- **Realtime**：WebSocket + 状态同步

#### 1.3、Row Level Security (RLS)：安全多租户
这是 Supabase 相比其他 BaaS 的杀手级特性：

```sql
-- 用户只能访问自己组织的数据
create policy "Users can only access their org data" on documents
for all using (
  exists (
    select 1 from memberships
    where user_id = auth.uid() and org_id = documents.org_id
  )
);
```

RLS 在数据库层面强制执行权限，即使应用层有 bug，也无法绕过安全策略。

#### 1.4、开源与自托管：避免厂商锁定
- **云服务**：快速开始，完整的运维支持
- **自托管**：数据主权，自定义扩展，成本可控
- **迁移友好**：标准 PostgreSQL，随时可以迁移到其他平台

### 2、技术边界：何时需要补充方案

#### 2.1、超大规模向量检索（> 500万向量）
**问题**：pgvector 在极大规模下的性能瓶颈
**解决方案**：
- **混合架构**：Supabase 存储元数据，专用向量库（Pinecone/Milvus）存储向量
- **分片策略**：按租户、时间或主题分片，降低单表规模

#### 2.2、复杂的 AI 推理管道
**问题**：Edge Functions 有 10MB 内存限制，不适合大模型推理
**解决方案**：
- **异步处理**：Edge Functions 接收请求 → 队列 → Worker 处理 → Webhook 回调
- **外部 AI 服务**：Edge Functions 作为代理，调用 OpenAI/Anthropic API

#### 2.3、实时协作的高并发场景
**问题**：Realtime 的连接数限制（免费版 200 并发）
**解决方案**：
- **分层架构**：核心状态用 Supabase Realtime，UI 层用 Socket.io
- **事件聚合**：减少推送频率，批量处理状态更新

### 3、业务场景适配度分析

#### 3.1、🟢 完美适配场景
- **AI 聊天应用**：对话历史 + 流式输出 + 多用户协作
- **知识库问答**：文档上传 + 向量检索 + 权限控制
- **代码助手**：代码片段存储 + 语义搜索 + 实时建议

#### 3.2、🟡 部分适配场景
- **大规模内容平台**：可能需要 CDN + 缓存层优化
- **高频交易 AI**：需要评估延迟要求，可能需要内存数据库

#### 3.3、🔴 不适配场景
- **大模型训练**：需要 GPU 集群，非 Supabase 目标场景
- **实时音视频 AI**：需要专用的流媒体服务

### 4、成本考量：TCO 分析

**开发成本**：Supabase 可以减少 60-80% 的后端开发时间
**运维成本**：托管服务消除了 DevOps 团队的必要性
**扩展成本**：按需付费，但大规模下可能比自建方案昂贵

**甜蜜点**：10-100 万用户的中等规模 AI 应用

## 三、参考架构（Web/移动 + Supabase 模块）

```
Client(Next.js/Expo)
  │
  ├─ Auth(JWT) ────────────┐
  │                        │
  ├─ Upload → Storage ──┐  │
  │                     │  │
  ├─ Chat/SSE/WebSocket │  │
  │                     │  │
  ▼                     ▼  ▼
Edge Functions (AI 网关/配额/日志)
  │     ├─ LLM 提供商调用（流式）
  │     ├─ 写 messages/usage_events
  │     └─ 触发向量入库管道
  ▼
Postgres + pgvector（业务表/向量表/RLS）
Realtime（会话/状态推送）
```

## 四、核心组件速览

- Auth + RLS：内置用户体系 + 行级安全，支持多租户隔离。
- Storage：文档与资源统一存储，Webhook/任务触发处理。
- pgvector：`vector` 列 + `ivfflat`/`hnsw` 索引，实现高效相似度检索。
- Edge Functions：鉴权网关、配额控制、流式代理、审计落库。
- Realtime：会话状态/协同编辑/进度条等实时体验。

## 五、关键实践一：鉴权与多租户

在 AI 应用中，多租户架构不仅是成本优化的需要，更是数据安全的基础。Supabase 的 `Row Level Security` (RLS) 提供了数据库级别的权限控制，这是其相对于 Firebase 等竞品的核心优势。

### 1、多租户数据模型设计

#### 1.1、层次化租户结构
```sql
-- 组织表：顶级租户
CREATE TABLE organizations (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  name TEXT NOT NULL,
  slug TEXT UNIQUE NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 项目表：二级租户
CREATE TABLE projects (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  name TEXT NOT NULL,
  description TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(org_id, name)
);

-- 成员关系表：权限管控
CREATE TABLE memberships (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  role TEXT CHECK (role IN ('owner', 'admin', 'member', 'viewer')),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(user_id, org_id)
);
```

#### 1.2、业务表设计原则
所有业务表都需要携带租户标识：

```sql
-- 文档表
CREATE TABLE documents (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  title TEXT NOT NULL,
  content TEXT,
  upload_user_id UUID REFERENCES auth.users(id),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 对话表
CREATE TABLE conversations (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
  title TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

### 2、策略设计模式

#### 2.1、基础组织级隔离
```sql
-- 用户只能访问自己所属组织的数据
CREATE POLICY "org_isolation_policy" ON documents
FOR ALL USING (
  EXISTS (
    SELECT 1 FROM memberships
    WHERE user_id = auth.uid()
      AND org_id = documents.org_id
  )
);
```

#### 2.2、角色基权限控制
```sql
-- 创建角色检查函数
CREATE OR REPLACE FUNCTION check_user_role(target_org_id UUID, required_role TEXT)
RETURNS BOOLEAN AS $$
BEGIN
  RETURN EXISTS (
    SELECT 1 FROM memberships
    WHERE user_id = auth.uid()
      AND org_id = target_org_id
      AND (
        CASE required_role
          WHEN 'viewer' THEN role IN ('viewer', 'member', 'admin', 'owner')
          WHEN 'member' THEN role IN ('member', 'admin', 'owner')
          WHEN 'admin' THEN role IN ('admin', 'owner')
          WHEN 'owner' THEN role = 'owner'
          ELSE FALSE
        END
      )
  );
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- 应用角色策略
CREATE POLICY "documents_select_policy" ON documents
FOR SELECT USING (check_user_role(org_id, 'viewer'));

CREATE POLICY "documents_insert_policy" ON documents
FOR INSERT WITH CHECK (check_user_role(org_id, 'member'));

CREATE POLICY "documents_update_policy" ON documents
FOR UPDATE USING (check_user_role(org_id, 'member'));

CREATE POLICY "documents_delete_policy" ON documents
FOR DELETE USING (check_user_role(org_id, 'admin'));
```

#### 2.3、项目级细粒度控制
```sql
-- 项目级权限表
CREATE TABLE project_permissions (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  permission TEXT CHECK (permission IN ('read', 'write', 'admin')),
  granted_by UUID REFERENCES auth.users(id),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  UNIQUE(user_id, project_id)
);

-- 项目级访问策略
CREATE POLICY "project_level_access" ON documents
FOR ALL USING (
  -- 组织成员 + 项目权限
  check_user_role(org_id, 'viewer') AND
  EXISTS (
    SELECT 1 FROM project_permissions pp
    WHERE pp.user_id = auth.uid()
      AND pp.project_id = documents.project_id
      AND pp.permission IN ('read', 'write', 'admin')
  )
);
```

### 3、体系与 API Key 管理

#### 3.1、用户 JWT Token
Supabase 自动处理用户认证，JWT 中包含 `user_id`，可在 RLS 中通过 `auth.uid()` 访问。

#### 3.2、项目级 API Key
用于服务间调用，实现最小权限原则：

```sql
-- API Key 表
CREATE TABLE api_keys (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  key_hash TEXT UNIQUE NOT NULL, -- 存储 hash，不存储明文
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  name TEXT NOT NULL,
  permissions JSONB DEFAULT '[]', -- ["documents:read", "conversations:write"]
  expires_at TIMESTAMPTZ,
  created_by UUID REFERENCES auth.users(id),
  last_used_at TIMESTAMPTZ,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  is_active BOOLEAN DEFAULT TRUE
);

-- API Key 权限检查函数
CREATE OR REPLACE FUNCTION check_api_key_permission(
  key_hash TEXT,
  required_permission TEXT
) RETURNS BOOLEAN AS $$
DECLARE
  key_record RECORD;
BEGIN
  SELECT * INTO key_record
  FROM api_keys
  WHERE key_hash = $1
    AND is_active = TRUE
    AND (expires_at IS NULL OR expires_at > NOW());

  IF NOT FOUND THEN
    RETURN FALSE;
  END IF;

  -- 更新最后使用时间
  UPDATE api_keys SET last_used_at = NOW() WHERE id = key_record.id;

  -- 检查权限
  RETURN key_record.permissions @> to_jsonb(required_permission);
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

#### 3.3、Edge Functions 中的权限验证
```typescript
// 在 Edge Functions 中验证 API Key
export async function validateApiKey(request: Request, requiredPermission: string) {
  const apiKey = request.headers.get('X-API-Key');
  if (!apiKey) {
    throw new Error('API Key required');
  }

  const keyHash = await crypto.subtle.digest(
    'SHA-256',
    new TextEncoder().encode(apiKey)
  );

  const { data, error } = await supabase.rpc('check_api_key_permission', {
    key_hash: Array.from(new Uint8Array(keyHash)).map(b => b.toString(16).padStart(2, '0')).join(''),
    required_permission: requiredPermission
  });

  if (error || !data) {
    throw new Error('Invalid API Key or insufficient permissions');
  }

  return true;
}
```

### 4、实际应用场景

#### 4.1、AI 聊天应用
- **组织隔离**：不同公司的对话记录完全隔离
- **项目权限**：同公司内不同项目的访问控制
- **角色权限**：管理员可以查看所有对话，普通用户只能看自己的

#### 4.2、知识库平台
- **文档级权限**：敏感文档只有特定角色可访问
- **向量数据同步**：RLS 确保向量检索也遵守权限规则
- **API 访问控制**：外部系统通过 API Key 访问特定项目数据

#### 4.3、代码助手
- **代码库隔离**：不同团队的代码严格隔离
- **功能权限**：读取代码 vs 生成代码的权限分离
- **审计追踪**：所有代码访问行为的完整记录

## 六、关键实践二：知识库与向量检索

知识库是 AI 应用的数据基础，而向量检索则是实现语义搜索的核心技术。Supabase 通过 `pgvector` 扩展提供了企业级的向量数据库能力，与传统关系数据无缝集成。

### 1、数据模型设计：三层架构

#### 1.1、文档层（Documents）
存储原始文档的元数据和内容：

```sql
CREATE TABLE documents (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,

  -- 文档基本信息
  title TEXT NOT NULL,
  content TEXT, -- 原始文本内容
  file_path TEXT, -- Storage 中的文件路径
  file_type TEXT CHECK (file_type IN ('pdf', 'docx', 'txt', 'md', 'html')),
  file_size BIGINT,

  -- 处理状态
  processing_status TEXT DEFAULT 'pending'
    CHECK (processing_status IN ('pending', 'processing', 'completed', 'failed')),
  error_message TEXT,

  -- 元数据
  metadata JSONB DEFAULT '{}',
  upload_user_id UUID REFERENCES auth.users(id),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 添加索引
CREATE INDEX idx_documents_org_project ON documents(org_id, project_id);
CREATE INDEX idx_documents_status ON documents(processing_status);
CREATE INDEX idx_documents_created_at ON documents(created_at DESC);
```

#### 1.2、分块层（Chunks）
将长文档切分为适合向量化的片段：

```sql
CREATE TABLE chunks (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  document_id UUID REFERENCES documents(id) ON DELETE CASCADE,

  -- 分块内容
  content TEXT NOT NULL,
  content_hash TEXT UNIQUE, -- 用于去重
  chunk_index INTEGER NOT NULL, -- 在文档中的顺序

  -- 分块元数据
  start_offset INTEGER, -- 在原文档中的起始位置
  end_offset INTEGER,   -- 在原文档中的结束位置
  token_count INTEGER,  -- token 数量估算

  -- 分块策略元数据
  chunk_strategy JSONB DEFAULT '{}', -- {"method": "recursive", "chunk_size": 1000, "overlap": 200}

  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 添加索引
CREATE INDEX idx_chunks_document ON chunks(document_id);
CREATE INDEX idx_chunks_hash ON chunks(content_hash);
CREATE UNIQUE INDEX idx_chunks_document_index ON chunks(document_id, chunk_index);
```

#### 1.3、向量层（Embeddings）
存储向量表示和检索索引：

```sql
-- 启用 pgvector 扩展
CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE embeddings (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  chunk_id UUID REFERENCES chunks(id) ON DELETE CASCADE,

  -- 向量数据
  vector vector(1536), -- OpenAI ada-002 的维度
  model_name TEXT NOT NULL DEFAULT 'text-embedding-ada-002',
  model_version TEXT,

  -- 向量元数据
  vector_norm REAL, -- 向量模长，用于归一化检查
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 向量索引：根据数据规模选择
-- 小于 100万向量：使用 ivfflat
CREATE INDEX idx_embeddings_vector_ivfflat
ON embeddings USING ivfflat (vector vector_cosine_ops)
WITH (lists = 100);

-- 大于 100万向量：使用 hnsw
-- CREATE INDEX idx_embeddings_vector_hnsw
-- ON embeddings USING hnsw (vector vector_cosine_ops)
-- WITH (m = 16, ef_construction = 64);

-- 业务索引
CREATE INDEX idx_embeddings_chunk ON embeddings(chunk_id);
CREATE INDEX idx_embeddings_model ON embeddings(model_name);
```

### 2、文档处理管道

#### 2.1、文档上传与预处理
通过 Supabase Storage 和 Edge Functions 构建处理管道：

```typescript
// Edge Function: document-upload
import { createClient } from '@supabase/supabase-js'

export async function handleDocumentUpload(request: Request) {
  const formData = await request.formData()
  const file = formData.get('file') as File
  const projectId = formData.get('project_id') as string

  // 1. 上传到 Storage
  const fileName = `${projectId}/${crypto.randomUUID()}-${file.name}`
  const { data: uploadData, error: uploadError } = await supabase.storage
    .from('documents')
    .upload(fileName, file)

  if (uploadError) throw uploadError

  // 2. 创建文档记录
  const { data: document, error: dbError } = await supabase
    .from('documents')
    .insert({
      title: file.name,
      file_path: uploadData.path,
      file_type: getFileType(file.name),
      file_size: file.size,
      project_id: projectId,
      processing_status: 'pending'
    })
    .select()
    .single()

  // 3. 触发异步处理
  await triggerDocumentProcessing(document.id)

  return new Response(JSON.stringify(document), { status: 200 })
}
```

#### 2.2、文本提取与分块
```typescript
// Edge Function: document-processor
export async function processDocument(documentId: string) {
  // 1. 获取文档信息
  const { data: document } = await supabase
    .from('documents')
    .select('*')
    .eq('id', documentId)
    .single()

  try {
    // 2. 更新状态为处理中
    await supabase
      .from('documents')
      .update({ processing_status: 'processing' })
      .eq('id', documentId)

    // 3. 从 Storage 下载文件
    const { data: fileData } = await supabase.storage
      .from('documents')
      .download(document.file_path)

    // 4. 提取文本内容
    const textContent = await extractText(fileData, document.file_type)

    // 5. 文本分块
    const chunks = await chunkText(textContent, {
      chunkSize: 1000,
      overlap: 200,
      strategy: 'recursive'
    })

    // 6. 批量插入分块
    const chunkInserts = chunks.map((chunk, index) => ({
      document_id: documentId,
      content: chunk.content,
      content_hash: hashContent(chunk.content),
      chunk_index: index,
      start_offset: chunk.startOffset,
      end_offset: chunk.endOffset,
      token_count: estimateTokens(chunk.content),
      chunk_strategy: { chunkSize: 1000, overlap: 200, strategy: 'recursive' }
    }))

    const { data: insertedChunks } = await supabase
      .from('chunks')
      .insert(chunkInserts)
      .select()

    // 7. 触发向量化
    await triggerEmbeddingGeneration(insertedChunks.map(c => c.id))

    // 8. 更新文档状态
    await supabase
      .from('documents')
      .update({
        content: textContent,
        processing_status: 'completed'
      })
      .eq('id', documentId)

  } catch (error) {
    // 错误处理
    await supabase
      .from('documents')
      .update({
        processing_status: 'failed',
        error_message: error.message
      })
      .eq('id', documentId)
  }
}
```

#### 2.3、向量生成与入库
```typescript
// Edge Function: embedding-generator
export async function generateEmbeddings(chunkIds: string[]) {
  const { data: chunks } = await supabase
    .from('chunks')
    .select('id, content')
    .in('id', chunkIds)

  for (const chunk of chunks) {
    try {
      // 调用 OpenAI Embedding API
      const response = await fetch('https://api.openai.com/v1/embeddings', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${OPENAI_API_KEY}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          input: chunk.content,
          model: 'text-embedding-ada-002'
        })
      })

      const embeddingData = await response.json()
      const vector = embeddingData.data[0].embedding

      // 计算向量模长（用于质量检查）
      const vectorNorm = Math.sqrt(vector.reduce((sum, val) => sum + val * val, 0))

      // 插入向量数据
      await supabase
        .from('embeddings')
        .insert({
          chunk_id: chunk.id,
          vector: vector,
          model_name: 'text-embedding-ada-002',
          vector_norm: vectorNorm
        })

    } catch (error) {
      console.error(`Failed to generate embedding for chunk ${chunk.id}:`, error)
    }
  }
}
```

### 3、语义检索实现

#### 3.1、基础相似度搜索
```sql
-- 创建相似度搜索函数
CREATE OR REPLACE FUNCTION search_similar_chunks(
  query_embedding vector(1536),
  match_threshold float DEFAULT 0.8,
  match_count int DEFAULT 10,
  target_org_id uuid DEFAULT NULL,
  target_project_id uuid DEFAULT NULL
)
RETURNS TABLE (
  chunk_id uuid,
  document_id uuid,
  content text,
  similarity float,
  document_title text
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    c.id as chunk_id,
    c.document_id,
    c.content,
    1 - (e.vector <=> query_embedding) as similarity,
    d.title as document_title
  FROM chunks c
  JOIN embeddings e ON c.id = e.chunk_id
  JOIN documents d ON c.document_id = d.id
  WHERE
    1 - (e.vector <=> query_embedding) > match_threshold
    AND (target_org_id IS NULL OR d.org_id = target_org_id)
    AND (target_project_id IS NULL OR d.project_id = target_project_id)
  ORDER BY e.vector <=> query_embedding
  LIMIT match_count;
END;
$$ LANGUAGE plpgsql;
```

#### 3.2、带权限控制的检索
```sql
-- 带 RLS 的搜索函数
CREATE OR REPLACE FUNCTION search_with_permissions(
  query_embedding vector(1536),
  match_threshold float DEFAULT 0.8,
  match_count int DEFAULT 10
)
RETURNS TABLE (
  chunk_id uuid,
  content text,
  similarity float,
  document_title text
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    c.id as chunk_id,
    c.content,
    1 - (e.vector <=> query_embedding) as similarity,
    d.title as document_title
  FROM chunks c
  JOIN embeddings e ON c.id = e.chunk_id
  JOIN documents d ON c.document_id = d.id
  WHERE
    1 - (e.vector <=> query_embedding) > match_threshold
    AND check_user_role(d.org_id, 'viewer') -- 确保用户有权限访问
  ORDER BY e.vector <=> query_embedding
  LIMIT match_count;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

#### 3.3、混合检索：向量 + 关键词
```sql
-- 混合检索函数
CREATE OR REPLACE FUNCTION hybrid_search(
  query_text text,
  query_embedding vector(1536),
  match_count int DEFAULT 10,
  semantic_weight float DEFAULT 0.7,
  keyword_weight float DEFAULT 0.3
)
RETURNS TABLE (
  chunk_id uuid,
  content text,
  combined_score float,
  semantic_similarity float,
  keyword_score float
) AS $$
BEGIN
  RETURN QUERY
  WITH semantic_results AS (
    SELECT
      c.id as chunk_id,
      c.content,
      1 - (e.vector <=> query_embedding) as similarity
    FROM chunks c
    JOIN embeddings e ON c.id = e.chunk_id
    JOIN documents d ON c.document_id = d.id
    WHERE check_user_role(d.org_id, 'viewer')
    ORDER BY e.vector <=> query_embedding
    LIMIT match_count * 2
  ),
  keyword_results AS (
    SELECT
      c.id as chunk_id,
      c.content,
      ts_rank(to_tsvector('english', c.content), plainto_tsquery('english', query_text)) as rank
    FROM chunks c
    JOIN documents d ON c.document_id = d.id
    WHERE
      to_tsvector('english', c.content) @@ plainto_tsquery('english', query_text)
      AND check_user_role(d.org_id, 'viewer')
    ORDER BY rank DESC
    LIMIT match_count * 2
  )
  SELECT
    COALESCE(s.chunk_id, k.chunk_id) as chunk_id,
    COALESCE(s.content, k.content) as content,
    (COALESCE(s.similarity, 0) * semantic_weight + COALESCE(k.rank, 0) * keyword_weight) as combined_score,
    COALESCE(s.similarity, 0) as semantic_similarity,
    COALESCE(k.rank, 0) as keyword_score
  FROM semantic_results s
  FULL OUTER JOIN keyword_results k ON s.chunk_id = k.chunk_id
  ORDER BY combined_score DESC
  LIMIT match_count;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

### 4、索引优化策略

#### 4.1、向量索引选择
```sql
-- 根据数据规模动态调整索引参数
DO $$
DECLARE
    vector_count bigint;
BEGIN
    SELECT COUNT(*) INTO vector_count FROM embeddings;

    IF vector_count < 100000 THEN
        -- 小规模：使用 ivfflat，lists = sqrt(vector_count)
        DROP INDEX IF EXISTS idx_embeddings_vector_hnsw;
        CREATE INDEX IF NOT EXISTS idx_embeddings_vector_ivfflat
        ON embeddings USING ivfflat (vector vector_cosine_ops)
        WITH (lists = GREATEST(10, LEAST(100, SQRT(vector_count)::int)));
    ELSE
        -- 大规模：使用 hnsw
        DROP INDEX IF EXISTS idx_embeddings_vector_ivfflat;
        CREATE INDEX IF NOT EXISTS idx_embeddings_vector_hnsw
        ON embeddings USING hnsw (vector vector_cosine_ops)
        WITH (m = 16, ef_construction = 64);
    END IF;
END $$;
```

#### 4.2、索引维护策略
```sql
-- 定期重建索引（在低峰期执行）
CREATE OR REPLACE FUNCTION rebuild_vector_index()
RETURNS void AS $$
BEGIN
  -- 重建索引前先分析表统计信息
  ANALYZE embeddings;

  -- 并发重建索引
  REINDEX INDEX CONCURRENTLY idx_embeddings_vector_ivfflat;

  -- 更新表统计信息
  ANALYZE embeddings;
END;
$$ LANGUAGE plpgsql;

-- 创建定时任务（需要 pg_cron 扩展）
-- SELECT cron.schedule('rebuild-vector-index', '0 2 * * 0', 'SELECT rebuild_vector_index();');
```

### 5、质量监控与优化

#### 5.1、检索质量指标
```sql
-- 创建检索日志表
CREATE TABLE search_logs (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id),
  org_id UUID REFERENCES organizations(id),
  query_text TEXT,
  query_embedding vector(1536),
  results JSONB, -- 返回的结果列表
  result_count INTEGER,
  search_time_ms INTEGER,
  clicked_results JSONB DEFAULT '[]', -- 用户点击的结果
  rating INTEGER CHECK (rating BETWEEN 1 AND 5), -- 用户评分
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 检索质量分析视图
CREATE VIEW search_quality_metrics AS
SELECT
  DATE_TRUNC('day', created_at) as date,
  org_id,
  COUNT(*) as total_searches,
  AVG(result_count) as avg_results,
  AVG(search_time_ms) as avg_search_time,
  AVG(rating) as avg_rating,
  AVG(JSONB_ARRAY_LENGTH(clicked_results)) as avg_clicks
FROM search_logs
WHERE created_at >= NOW() - INTERVAL '30 days'
GROUP BY DATE_TRUNC('day', created_at), org_id
ORDER BY date DESC;
```

#### 5.2、向量质量检查
```sql
-- 检查向量质量
CREATE OR REPLACE FUNCTION check_vector_quality()
RETURNS TABLE (
  model_name text,
  total_vectors bigint,
  avg_norm float,
  zero_vectors bigint,
  invalid_vectors bigint
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    e.model_name,
    COUNT(*) as total_vectors,
    AVG(e.vector_norm) as avg_norm,
    COUNT(*) FILTER (WHERE e.vector_norm = 0) as zero_vectors,
    COUNT(*) FILTER (WHERE e.vector_norm IS NULL OR e.vector_norm < 0.1) as invalid_vectors
  FROM embeddings e
  GROUP BY e.model_name;
END;
$$ LANGUAGE plpgsql;
```

这个向量检索系统提供了：
- **企业级数据隔离**：通过 RLS 确保租户间数据安全
- **高性能检索**：向量索引 + 混合搜索
- **可观测性**：质量监控和性能指标
- **可扩展性**：支持从小规模到大规模的平滑扩展

## 七、关键实践三：流式推理接口

AI 应用的用户体验核心在于"感知智能"，而流式输出是实现这种体验的关键技术。Supabase 的 Edge Functions + Realtime 组合为构建流式 AI 接口提供了完整的解决方案。

### 1、流式架构设计

#### 1.1、SSE (Server-Sent Events) 实现
Edge Functions 天然支持流式响应，适合简单的单向数据流：

```typescript
// Edge Function: chat-stream
export async function handleChatStream(request: Request) {
  const { message, conversationId, projectId } = await request.json()

  // 创建流式响应
  const stream = new ReadableStream({
    async start(controller) {
      try {
        // 1. 记录用户消息
        const userMessage = await saveMessage({
          conversationId,
          role: 'user',
          content: message,
          projectId
        })

        // 2. 创建助手消息占位符
        const assistantMessage = await saveMessage({
          conversationId,
          role: 'assistant',
          content: '',
          projectId,
          status: 'streaming'
        })

        // 3. 调用 AI 服务（OpenAI/Anthropic）
        const completion = await openai.chat.completions.create({
          model: 'gpt-4',
          messages: await buildMessageHistory(conversationId),
          stream: true,
          temperature: 0.7,
        })

        let fullContent = ''

        // 4. 流式处理 AI 响应
        for await (const chunk of completion) {
          const delta = chunk.choices[0]?.delta?.content || ''

          if (delta) {
            fullContent += delta

            // 发送增量内容
            const data = JSON.stringify({
              type: 'content_delta',
              messageId: assistantMessage.id,
              delta: delta,
              fullContent: fullContent
            })

            controller.enqueue(new TextEncoder().encode(`data: ${data}\n\n`))

            // 定期更新数据库（每100个字符或每2秒）
            if (fullContent.length % 100 === 0) {
              await updateMessage(assistantMessage.id, {
                content: fullContent,
                updated_at: new Date().toISOString()
              })
            }
          }
        }

        // 5. 完成流式传输
        await updateMessage(assistantMessage.id, {
          content: fullContent,
          status: 'completed',
          token_count: estimateTokens(fullContent)
        })

        // 6. 记录用量事件
        await recordUsageEvent({
          conversationId,
          userId: userMessage.user_id,
          projectId,
          inputTokens: estimateTokens(message),
          outputTokens: estimateTokens(fullContent),
          model: 'gpt-4'
        })

        controller.enqueue(new TextEncoder().encode(`data: {"type": "done"}\n\n`))
        controller.close()

      } catch (error) {
        console.error('Stream error:', error)
        controller.enqueue(
          new TextEncoder().encode(`data: {"type": "error", "message": "${error.message}"}\n\n`)
        )
        controller.close()
      }
    }
  })

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive'
    }
  })
}
```

#### 1.2、WebSocket + Realtime 实现
对于需要双向通信的复杂场景，使用 Supabase Realtime：

```typescript
// 前端：建立 Realtime 连接
const setupRealtimeChat = (conversationId: string) => {
  const channel = supabase
    .channel(`conversation:${conversationId}`)
    .on('postgres_changes', {
      event: 'UPDATE',
      schema: 'public',
      table: 'messages',
      filter: `conversation_id=eq.${conversationId}`
    }, (payload) => {
      handleMessageUpdate(payload.new)
    })
    .on('postgres_changes', {
      event: 'INSERT',
      schema: 'public',
      table: 'messages',
      filter: `conversation_id=eq.${conversationId}`
    }, (payload) => {
      handleNewMessage(payload.new)
    })
    .subscribe()

  return channel
}

// 处理消息更新
const handleMessageUpdate = (message: any) => {
  if (message.status === 'streaming') {
    // 流式更新消息内容
    updateMessageInUI(message.id, message.content)
  } else if (message.status === 'completed') {
    // 消息完成，更新 UI 状态
    markMessageComplete(message.id)
  }
}
```

#### 1.3、混合方案：SSE + DB 推送
结合 SSE 的低延迟和数据库的持久化：

```typescript
// Edge Function: hybrid-chat
export async function handleHybridChat(request: Request) {
  const { message, conversationId } = await request.json()

  const stream = new ReadableStream({
    async start(controller) {
      let buffer = ''
      let lastDbUpdate = Date.now()

      for await (const chunk of aiCompletion) {
        const delta = chunk.choices[0]?.delta?.content || ''
        buffer += delta

        // 立即推送到客户端
        controller.enqueue(new TextEncoder().encode(`data: ${JSON.stringify({
          type: 'delta',
          content: delta
        })}\n\n`))

        // 每500ms或累积100字符时更新数据库
        const now = Date.now()
        if (now - lastDbUpdate > 500 || buffer.length % 100 === 0) {
          await updateMessageContent(messageId, buffer)
          lastDbUpdate = now

          // 触发 Realtime 更新
          await supabase
            .from('message_updates')
            .insert({
              message_id: messageId,
              content: buffer,
              timestamp: new Date().toISOString()
            })
        }
      }
    }
  })
}
```

### 2、数据模型：对话与消息

#### 2.1、对话表
```sql
CREATE TABLE conversations (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,

  title TEXT,
  system_prompt TEXT,
  model_config JSONB DEFAULT '{}', -- {"model": "gpt-4", "temperature": 0.7}

  status TEXT DEFAULT 'active' CHECK (status IN ('active', 'archived', 'deleted')),
  message_count INTEGER DEFAULT 0,
  total_tokens INTEGER DEFAULT 0,

  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 添加索引
CREATE INDEX idx_conversations_user_updated ON conversations(user_id, updated_at DESC);
CREATE INDEX idx_conversations_project ON conversations(project_id);
```

#### 2.2、消息表
```sql
CREATE TABLE messages (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  conversation_id UUID REFERENCES conversations(id) ON DELETE CASCADE,

  role TEXT NOT NULL CHECK (role IN ('system', 'user', 'assistant', 'tool')),
  content TEXT NOT NULL,
  content_type TEXT DEFAULT 'text' CHECK (content_type IN ('text', 'image', 'audio', 'file')),

  -- 流式状态
  status TEXT DEFAULT 'completed' CHECK (status IN ('pending', 'streaming', 'completed', 'failed')),
  stream_position INTEGER DEFAULT 0, -- 流式输出的当前位置

  -- AI 相关元数据
  model_name TEXT,
  token_count INTEGER,
  finish_reason TEXT,
  tool_calls JSONB,

  -- 引用与关联
  parent_message_id UUID REFERENCES messages(id),
  references JSONB DEFAULT '[]', -- 引用的文档/代码片段

  -- 质量控制
  rating INTEGER CHECK (rating BETWEEN 1 AND 5),
  feedback TEXT,

  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 添加索引
CREATE INDEX idx_messages_conversation ON messages(conversation_id, created_at);
CREATE INDEX idx_messages_status ON messages(status) WHERE status != 'completed';
CREATE INDEX idx_messages_streaming ON messages(conversation_id, stream_position) WHERE status = 'streaming';
```

### 3、容错与重试机制

#### 3.1、幂等性保证
```typescript
// 使用幂等键防止重复处理
export async function handleChatWithIdempotency(request: Request) {
  const idempotencyKey = request.headers.get('Idempotency-Key')
  if (!idempotencyKey) {
    throw new Error('Idempotency-Key header required')
  }

  // 检查是否已处理
  const existing = await supabase
    .from('idempotency_keys')
    .select('response_data, status')
    .eq('key', idempotencyKey)
    .single()

  if (existing.data) {
    if (existing.data.status === 'completed') {
      // 返回缓存的结果
      return new Response(existing.data.response_data)
    } else if (existing.data.status === 'processing') {
      // 正在处理中，返回 409
      return new Response('Request is being processed', { status: 409 })
    }
  }

  // 记录处理开始
  await supabase
    .from('idempotency_keys')
    .upsert({
      key: idempotencyKey,
      status: 'processing',
      created_at: new Date().toISOString()
    })

  try {
    const result = await processChatRequest(request)

    // 记录成功结果
    await supabase
      .from('idempotency_keys')
      .update({
        status: 'completed',
        response_data: await result.text(),
        completed_at: new Date().toISOString()
      })
      .eq('key', idempotencyKey)

    return result
  } catch (error) {
    // 记录失败状态
    await supabase
      .from('idempotency_keys')
      .update({
        status: 'failed',
        error_message: error.message,
        failed_at: new Date().toISOString()
      })
      .eq('key', idempotencyKey)

    throw error
  }
}
```

#### 3.2、断点续传
```typescript
// 支持长响应的断点续传
export async function resumeStreamingMessage(messageId: string) {
  const { data: message } = await supabase
    .from('messages')
    .select('content, stream_position, conversation_id')
    .eq('id', messageId)
    .single()

  if (message.status !== 'streaming') {
    throw new Error('Message is not in streaming state')
  }

  // 从中断位置继续生成
  const completion = await openai.chat.completions.create({
    model: 'gpt-4',
    messages: await buildMessageHistory(message.conversation_id),
    stream: true,
    // 传递已生成的内容作为 context
    prompt: message.content,
    continue_from: message.stream_position
  })

  // 继续流式处理...
}
```

### 4、性能优化策略

#### 4.1、连接池管理
```typescript
// Edge Functions 中的连接复用
const aiClientPool = new Map<string, OpenAI>()

function getAIClient(apiKey: string): OpenAI {
  if (!aiClientPool.has(apiKey)) {
    aiClientPool.set(apiKey, new OpenAI({
      apiKey,
      maxRetries: 3,
      timeout: 30000
    }))
  }
  return aiClientPool.get(apiKey)!
}
```

#### 4.2、分块传输优化
```typescript
// 智能分块策略
function createChunkedStream(content: string) {
  return new ReadableStream({
    start(controller) {
      const sentences = content.split(/[.!?]+/)

      for (const sentence of sentences) {
        // 按句子分块，提升阅读体验
        controller.enqueue(new TextEncoder().encode(
          `data: ${JSON.stringify({ delta: sentence + '. ' })}\n\n`
        ))

        // 句子间添加小延迟，模拟思考过程
        await new Promise(resolve => setTimeout(resolve, 50))
      }

      controller.close()
    }
  })
}
```

#### 4.3、缓存策略
```typescript
// 响应缓存（相同问题的快速响应）
export async function getCachedResponse(
  messageHistory: Message[],
  cacheKey: string
) {
  const { data: cached } = await supabase
    .from('response_cache')
    .select('response, created_at')
    .eq('cache_key', cacheKey)
    .gte('created_at', new Date(Date.now() - 3600000).toISOString()) // 1小时内有效
    .single()

  if (cached) {
    return cached.response
  }

  // 生成新响应并缓存
  const response = await generateAIResponse(messageHistory)

  await supabase
    .from('response_cache')
    .insert({
      cache_key: cacheKey,
      response: response,
      expires_at: new Date(Date.now() + 3600000).toISOString()
    })

  return response
}
```

## 八、关键实践四：用量统计与配额

AI 应用的商业模式往往基于使用量计费，精确的用量统计和灵活的配额管理是产品成功的关键。Supabase 的事务能力和实时特性为构建企业级计费系统提供了坚实基础。

### 1、用量事件模型

#### 1.1、事件驱动架构
```sql
-- 用量事件表：记录所有可计费的操作
CREATE TABLE usage_events (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,

  -- 租户信息
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,

  -- 事件分类
  event_type TEXT NOT NULL, -- 'chat_completion', 'embedding', 'document_processing', 'api_call'
  event_subtype TEXT, -- 'gpt-4', 'gpt-3.5-turbo', 'text-embedding-ada-002'

  -- 用量数据
  input_tokens INTEGER DEFAULT 0,
  output_tokens INTEGER DEFAULT 0,
  total_tokens INTEGER GENERATED ALWAYS AS (input_tokens + output_tokens) STORED,

  -- 成本计算
  input_cost DECIMAL(10,6) DEFAULT 0, -- 精确到微分
  output_cost DECIMAL(10,6) DEFAULT 0,
  total_cost DECIMAL(10,6) GENERATED ALWAYS AS (input_cost + output_cost) STORED,

  -- 上下文信息
  conversation_id UUID REFERENCES conversations(id),
  message_id UUID REFERENCES messages(id),
  document_id UUID REFERENCES documents(id),

  -- 元数据
  model_config JSONB,
  processing_time_ms INTEGER,
  error_message TEXT,

  -- 时间信息
  started_at TIMESTAMPTZ DEFAULT NOW(),
  completed_at TIMESTAMPTZ,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 分区表（按月分区，提升查询性能）
CREATE TABLE usage_events_y2024m01 PARTITION OF usage_events
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
CREATE TABLE usage_events_y2024m02 PARTITION OF usage_events
FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
-- ... 继续创建其他月份分区

-- 高性能索引
CREATE INDEX idx_usage_events_org_time ON usage_events(org_id, created_at DESC);
CREATE INDEX idx_usage_events_user_time ON usage_events(user_id, created_at DESC);
CREATE INDEX idx_usage_events_project_time ON usage_events(project_id, created_at DESC);
CREATE INDEX idx_usage_events_type_time ON usage_events(event_type, created_at DESC);
```

#### 1.2、定价模型配置
```sql
-- 定价规则表
CREATE TABLE pricing_rules (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,

  -- 规则标识
  rule_name TEXT UNIQUE NOT NULL,
  event_type TEXT NOT NULL,
  event_subtype TEXT,

  -- 定价策略
  pricing_model TEXT NOT NULL CHECK (pricing_model IN ('per_token', 'per_request', 'per_duration', 'tiered')),

  -- 基础价格（每千 token 的价格）
  base_input_price DECIMAL(10,6) DEFAULT 0,
  base_output_price DECIMAL(10,6) DEFAULT 0,

  -- 阶梯定价
  tiers JSONB, -- [{"from": 0, "to": 10000, "multiplier": 1.0}, {"from": 10000, "to": 100000, "multiplier": 0.9}]

  -- 时间有效性
  effective_from TIMESTAMPTZ DEFAULT NOW(),
  effective_to TIMESTAMPTZ,

  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 插入定价规则示例
INSERT INTO pricing_rules (rule_name, event_type, event_subtype, pricing_model, base_input_price, base_output_price) VALUES
('gpt-4-standard', 'chat_completion', 'gpt-4', 'per_token', 0.00003, 0.00006),
('gpt-3.5-standard', 'chat_completion', 'gpt-3.5-turbo', 'per_token', 0.000001, 0.000002),
('embedding-ada-002', 'embedding', 'text-embedding-ada-002', 'per_token', 0.0000001, 0);
```

#### 1.3、实时成本计算
```sql
-- 成本计算函数
CREATE OR REPLACE FUNCTION calculate_usage_cost(
  p_event_type TEXT,
  p_event_subtype TEXT,
  p_input_tokens INTEGER,
  p_output_tokens INTEGER,
  p_org_id UUID DEFAULT NULL
) RETURNS TABLE (
  input_cost DECIMAL(10,6),
  output_cost DECIMAL(10,6),
  total_cost DECIMAL(10,6)
) AS $$
DECLARE
  pricing_rule RECORD;
  monthly_usage BIGINT;
  tier_multiplier DECIMAL(4,3) := 1.0;
BEGIN
  -- 获取适用的定价规则
  SELECT * INTO pricing_rule
  FROM pricing_rules
  WHERE event_type = p_event_type
    AND (event_subtype IS NULL OR event_subtype = p_event_subtype)
    AND effective_from <= NOW()
    AND (effective_to IS NULL OR effective_to > NOW())
  ORDER BY effective_from DESC
  LIMIT 1;

  IF NOT FOUND THEN
    RAISE EXCEPTION 'No pricing rule found for event_type: %, event_subtype: %', p_event_type, p_event_subtype;
  END IF;

  -- 计算阶梯定价倍数
  IF pricing_rule.pricing_model = 'tiered' AND p_org_id IS NOT NULL THEN
    SELECT COALESCE(SUM(total_tokens), 0) INTO monthly_usage
    FROM usage_events
    WHERE org_id = p_org_id
      AND event_type = p_event_type
      AND created_at >= DATE_TRUNC('month', NOW());

    -- 根据月度用量确定阶梯倍数
    SELECT COALESCE(
      (SELECT (tier->>'multiplier')::DECIMAL
       FROM jsonb_array_elements(pricing_rule.tiers) AS tier
       WHERE monthly_usage >= (tier->>'from')::BIGINT
         AND (tier->>'to' IS NULL OR monthly_usage < (tier->>'to')::BIGINT)
       LIMIT 1), 1.0
    ) INTO tier_multiplier;
  END IF;

  -- 计算最终成本
  RETURN QUERY SELECT
    (p_input_tokens * pricing_rule.base_input_price * tier_multiplier / 1000)::DECIMAL(10,6),
    (p_output_tokens * pricing_rule.base_output_price * tier_multiplier / 1000)::DECIMAL(10,6),
    ((p_input_tokens * pricing_rule.base_input_price + p_output_tokens * pricing_rule.base_output_price) * tier_multiplier / 1000)::DECIMAL(10,6);
END;
$$ LANGUAGE plpgsql;
```

### 2、配额管理系统

#### 2.1、配额配置
```sql
-- 配额规则表
CREATE TABLE quota_rules (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,

  -- 适用范围
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,

  -- 配额类型
  quota_type TEXT NOT NULL, -- 'tokens', 'requests', 'cost', 'concurrent'
  event_type TEXT, -- 限制特定事件类型

  -- 配额限制
  quota_limit BIGINT NOT NULL,
  quota_period TEXT NOT NULL CHECK (quota_period IN ('minute', 'hour', 'day', 'month')),

  -- 重置策略
  reset_schedule TEXT, -- cron 表达式
  carry_over BOOLEAN DEFAULT FALSE, -- 是否允许未用完的配额结转

  -- 超限行为
  enforcement_action TEXT DEFAULT 'block' CHECK (enforcement_action IN ('block', 'warn', 'throttle')),

  -- 时间有效性
  effective_from TIMESTAMPTZ DEFAULT NOW(),
  effective_to TIMESTAMPTZ,

  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 配额使用记录
CREATE TABLE quota_usage (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  quota_rule_id UUID REFERENCES quota_rules(id) ON DELETE CASCADE,

  -- 使用情况
  period_start TIMESTAMPTZ NOT NULL,
  period_end TIMESTAMPTZ NOT NULL,
  current_usage BIGINT DEFAULT 0,
  quota_limit BIGINT NOT NULL,

  -- 状态
  is_exceeded BOOLEAN DEFAULT FALSE,
  last_reset_at TIMESTAMPTZ,

  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

#### 2.2、实时配额检查
```sql
-- 配额检查函数
CREATE OR REPLACE FUNCTION check_quota_limits(
  p_org_id UUID,
  p_project_id UUID DEFAULT NULL,
  p_user_id UUID DEFAULT NULL,
  p_event_type TEXT DEFAULT NULL,
  p_requested_amount BIGINT DEFAULT 1
) RETURNS TABLE (
  is_allowed BOOLEAN,
  quota_type TEXT,
  current_usage BIGINT,
  quota_limit BIGINT,
  remaining BIGINT
) AS $$
DECLARE
  quota_rule RECORD;
  current_period_start TIMESTAMPTZ;
  current_period_end TIMESTAMPTZ;
  usage_amount BIGINT;
BEGIN
  -- 检查所有适用的配额规则
  FOR quota_rule IN
    SELECT qr.* FROM quota_rules qr
    WHERE (qr.org_id = p_org_id OR qr.org_id IS NULL)
      AND (qr.project_id = p_project_id OR qr.project_id IS NULL)
      AND (qr.user_id = p_user_id OR qr.user_id IS NULL)
      AND (qr.event_type = p_event_type OR qr.event_type IS NULL)
      AND qr.effective_from <= NOW()
      AND (qr.effective_to IS NULL OR qr.effective_to > NOW())
    ORDER BY
      CASE WHEN qr.user_id IS NOT NULL THEN 1 ELSE 2 END,
      CASE WHEN qr.project_id IS NOT NULL THEN 1 ELSE 2 END,
      CASE WHEN qr.org_id IS NOT NULL THEN 1 ELSE 2 END
  LOOP
    -- 计算当前周期
    CASE quota_rule.quota_period
      WHEN 'minute' THEN
        current_period_start := DATE_TRUNC('minute', NOW());
        current_period_end := current_period_start + INTERVAL '1 minute';
      WHEN 'hour' THEN
        current_period_start := DATE_TRUNC('hour', NOW());
        current_period_end := current_period_start + INTERVAL '1 hour';
      WHEN 'day' THEN
        current_period_start := DATE_TRUNC('day', NOW());
        current_period_end := current_period_start + INTERVAL '1 day';
      WHEN 'month' THEN
        current_period_start := DATE_TRUNC('month', NOW());
        current_period_end := current_period_start + INTERVAL '1 month';
    END CASE;

    -- 获取当前周期使用量
    SELECT
      CASE quota_rule.quota_type
        WHEN 'tokens' THEN COALESCE(SUM(total_tokens), 0)
        WHEN 'requests' THEN COUNT(*)
        WHEN 'cost' THEN COALESCE(SUM(total_cost * 1000000), 0)::BIGINT -- 转换为微分
        ELSE 0
      END
    INTO usage_amount
    FROM usage_events ue
    WHERE ue.created_at >= current_period_start
      AND ue.created_at < current_period_end
      AND (quota_rule.org_id IS NULL OR ue.org_id = quota_rule.org_id)
      AND (quota_rule.project_id IS NULL OR ue.project_id = quota_rule.project_id)
      AND (quota_rule.user_id IS NULL OR ue.user_id = quota_rule.user_id)
      AND (quota_rule.event_type IS NULL OR ue.event_type = quota_rule.event_type);

    -- 检查是否超限
    IF usage_amount + p_requested_amount > quota_rule.quota_limit THEN
      RETURN QUERY SELECT
        FALSE,
        quota_rule.quota_type,
        usage_amount,
        quota_rule.quota_limit,
        GREATEST(0, quota_rule.quota_limit - usage_amount);
      RETURN;
    END IF;
  END LOOP;

  -- 所有配额检查通过
  RETURN QUERY SELECT TRUE, ''::TEXT, 0::BIGINT, 0::BIGINT, 0::BIGINT;
END;
$$ LANGUAGE plpgsql;
```

### 3、聚合视图与报表

#### 3.1、实时使用量统计
```sql
-- 组织级使用量视图
CREATE VIEW org_usage_summary AS
SELECT
  ue.org_id,
  o.name as org_name,
  DATE_TRUNC('day', ue.created_at) as usage_date,
  ue.event_type,
  COUNT(*) as request_count,
  SUM(ue.input_tokens) as total_input_tokens,
  SUM(ue.output_tokens) as total_output_tokens,
  SUM(ue.total_tokens) as total_tokens,
  SUM(ue.total_cost) as total_cost,
  AVG(ue.processing_time_ms) as avg_processing_time
FROM usage_events ue
JOIN organizations o ON ue.org_id = o.id
WHERE ue.created_at >= NOW() - INTERVAL '30 days'
GROUP BY ue.org_id, o.name, DATE_TRUNC('day', ue.created_at), ue.event_type
ORDER BY usage_date DESC, total_cost DESC;

-- 用户级使用量视图
CREATE VIEW user_usage_summary AS
SELECT
  ue.user_id,
  p.email as user_email,
  ue.org_id,
  DATE_TRUNC('hour', ue.created_at) as usage_hour,
  COUNT(*) as request_count,
  SUM(ue.total_tokens) as total_tokens,
  SUM(ue.total_cost) as total_cost
FROM usage_events ue
JOIN auth.users p ON ue.user_id = p.id
WHERE ue.created_at >= NOW() - INTERVAL '7 days'
GROUP BY ue.user_id, p.email, ue.org_id, DATE_TRUNC('hour', ue.created_at)
ORDER BY usage_hour DESC, total_cost DESC;
```

#### 3.2、配额使用率监控
```sql
-- 配额使用率视图
CREATE VIEW quota_utilization AS
WITH current_usage AS (
  SELECT
    qr.id as quota_rule_id,
    qr.quota_type,
    qr.quota_limit,
    qr.quota_period,
    qr.org_id,
    qr.project_id,
    qr.user_id,
    CASE qr.quota_period
      WHEN 'minute' THEN DATE_TRUNC('minute', NOW())
      WHEN 'hour' THEN DATE_TRUNC('hour', NOW())
      WHEN 'day' THEN DATE_TRUNC('day', NOW())
      WHEN 'month' THEN DATE_TRUNC('month', NOW())
    END as period_start,
    CASE qr.quota_type
      WHEN 'tokens' THEN COALESCE(SUM(ue.total_tokens), 0)
      WHEN 'requests' THEN COUNT(ue.id)
      WHEN 'cost' THEN COALESCE(SUM(ue.total_cost * 1000000), 0)::BIGINT
      ELSE 0
    END as current_usage
  FROM quota_rules qr
  LEFT JOIN usage_events ue ON (
    (qr.org_id IS NULL OR ue.org_id = qr.org_id) AND
    (qr.project_id IS NULL OR ue.project_id = qr.project_id) AND
    (qr.user_id IS NULL OR ue.user_id = qr.user_id) AND
    (qr.event_type IS NULL OR ue.event_type = qr.event_type) AND
    ue.created_at >= CASE qr.quota_period
      WHEN 'minute' THEN DATE_TRUNC('minute', NOW())
      WHEN 'hour' THEN DATE_TRUNC('hour', NOW())
      WHEN 'day' THEN DATE_TRUNC('day', NOW())
      WHEN 'month' THEN DATE_TRUNC('month', NOW())
    END
  )
  WHERE qr.effective_from <= NOW()
    AND (qr.effective_to IS NULL OR qr.effective_to > NOW())
  GROUP BY qr.id, qr.quota_type, qr.quota_limit, qr.quota_period, qr.org_id, qr.project_id, qr.user_id
)
SELECT
  quota_rule_id,
  quota_type,
  quota_limit,
  quota_period,
  org_id,
  project_id,
  user_id,
  current_usage,
  ROUND((current_usage::DECIMAL / quota_limit * 100), 2) as utilization_percentage,
  GREATEST(0, quota_limit - current_usage) as remaining_quota,
  CASE
    WHEN current_usage >= quota_limit THEN 'EXCEEDED'
    WHEN current_usage >= quota_limit * 0.9 THEN 'WARNING'
    WHEN current_usage >= quota_limit * 0.7 THEN 'MODERATE'
    ELSE 'NORMAL'
  END as status
FROM current_usage
ORDER BY utilization_percentage DESC;
```

### 4、计费集成

#### 4.1、发票生成
```sql
-- 发票表
CREATE TABLE invoices (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,

  -- 发票信息
  invoice_number TEXT UNIQUE NOT NULL,
  billing_period_start DATE NOT NULL,
  billing_period_end DATE NOT NULL,

  -- 金额信息
  subtotal DECIMAL(10,2) NOT NULL,
  tax_amount DECIMAL(10,2) DEFAULT 0,
  total_amount DECIMAL(10,2) NOT NULL,

  -- 状态
  status TEXT DEFAULT 'draft' CHECK (status IN ('draft', 'sent', 'paid', 'overdue', 'cancelled')),
  due_date DATE,
  paid_at TIMESTAMPTZ,

  -- 元数据
  line_items JSONB, -- 详细的计费项目

  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 生成月度发票函数
CREATE OR REPLACE FUNCTION generate_monthly_invoice(
  p_org_id UUID,
  p_billing_month DATE
) RETURNS UUID AS $$
DECLARE
  invoice_id UUID;
  line_items JSONB := '[]'::JSONB;
  total_cost DECIMAL(10,2) := 0;
BEGIN
  -- 汇总当月使用量
  WITH monthly_usage AS (
    SELECT
      event_type,
      event_subtype,
      SUM(total_tokens) as total_tokens,
      SUM(total_cost) as cost
    FROM usage_events
    WHERE org_id = p_org_id
      AND created_at >= DATE_TRUNC('month', p_billing_month)
      AND created_at < DATE_TRUNC('month', p_billing_month) + INTERVAL '1 month'
    GROUP BY event_type, event_subtype
  )
  SELECT jsonb_agg(
    jsonb_build_object(
      'service', event_type || COALESCE('/' || event_subtype, ''),
      'quantity', total_tokens,
      'unit_price', ROUND(cost / total_tokens * 1000, 6),
      'total', cost
    )
  ), SUM(cost)
  INTO line_items, total_cost
  FROM monthly_usage;

  -- 创建发票
  INSERT INTO invoices (
    org_id,
    invoice_number,
    billing_period_start,
    billing_period_end,
    subtotal,
    total_amount,
    line_items,
    due_date
  ) VALUES (
    p_org_id,
    'INV-' || TO_CHAR(p_billing_month, 'YYYY-MM') || '-' || p_org_id,
    DATE_TRUNC('month', p_billing_month),
    DATE_TRUNC('month', p_billing_month) + INTERVAL '1 month' - INTERVAL '1 day',
    total_cost,
    total_cost,
    line_items,
    DATE_TRUNC('month', p_billing_month) + INTERVAL '1 month' + INTERVAL '15 days'
  ) RETURNING id INTO invoice_id;

  RETURN invoice_id;
END;
$$ LANGUAGE plpgsql;
```

这个用量统计与配额系统提供了：
- **精确计费**：基于实际使用量的精确成本计算
- **灵活配额**：多级配额控制，支持各种限流策略
- **实时监控**：使用量和配额的实时监控与告警
- **财务集成**：完整的发票生成和计费流程

## 九、数据模型设计要点

设计良好的数据模型是 AI 应用成功的基础。在 Supabase 环境中，需要平衡关系数据库的 ACID 特性与向量检索的性能需求，同时考虑多租户安全和扩展性。

### 1、核心实体关系

#### 1.1、租户与权限层次
```sql
-- 租户层次：Organization → Project → User
-- 支持企业级多租户和项目级隔离

-- 扩展 auth.users 表
CREATE TABLE user_profiles (
  id UUID REFERENCES auth.users(id) PRIMARY KEY,
  display_name TEXT,
  avatar_url TEXT,
  timezone TEXT DEFAULT 'UTC',
  preferences JSONB DEFAULT '{}',
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 组织表：顶级租户
CREATE TABLE organizations (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  name TEXT NOT NULL,
  slug TEXT UNIQUE NOT NULL,
  domain TEXT, -- 企业邮箱域名，用于自动邀请
  settings JSONB DEFAULT '{}',
  subscription_plan TEXT DEFAULT 'free',
  subscription_status TEXT DEFAULT 'active',
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 项目表：二级租户
CREATE TABLE projects (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  name TEXT NOT NULL,
  description TEXT,
  settings JSONB DEFAULT '{}', -- AI 模型配置、默认参数等
  is_archived BOOLEAN DEFAULT FALSE,
  created_by UUID REFERENCES auth.users(id),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),

  CONSTRAINT unique_project_name_per_org UNIQUE(org_id, name)
);

-- 成员关系表：灵活的角色权限
CREATE TABLE memberships (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,

  -- 角色权限
  role TEXT NOT NULL CHECK (role IN ('owner', 'admin', 'member', 'viewer')),
  permissions JSONB DEFAULT '[]', -- 额外的细粒度权限

  -- 邀请流程
  invited_by UUID REFERENCES auth.users(id),
  invited_at TIMESTAMPTZ,
  joined_at TIMESTAMPTZ,
  status TEXT DEFAULT 'active' CHECK (status IN ('pending', 'active', 'suspended')),

  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),

  CONSTRAINT unique_user_org UNIQUE(user_id, org_id)
);

-- 项目权限表：项目级细粒度控制
CREATE TABLE project_memberships (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,

  permission_level TEXT NOT NULL CHECK (permission_level IN ('read', 'write', 'admin')),
  granted_by UUID REFERENCES auth.users(id),

  created_at TIMESTAMPTZ DEFAULT NOW(),

  CONSTRAINT unique_user_project UNIQUE(user_id, project_id)
);
```

#### 1.2、知识库与内容管理
```sql
-- 知识库：文档 → 分块 → 向量的三层架构

-- 文档集合表（可选，用于组织文档）
CREATE TABLE document_collections (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,

  name TEXT NOT NULL,
  description TEXT,
  metadata JSONB DEFAULT '{}',

  created_by UUID REFERENCES auth.users(id),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 文档表：增强版本，支持版本控制
CREATE TABLE documents (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  collection_id UUID REFERENCES document_collections(id) ON DELETE SET NULL,

  -- 文档信息
  title TEXT NOT NULL,
  content TEXT, -- 提取后的纯文本
  content_hash TEXT, -- 内容哈希，用于去重和变更检测

  -- 文件信息
  file_path TEXT, -- Storage 路径
  file_name TEXT,
  file_type TEXT,
  file_size BIGINT,
  mime_type TEXT,

  -- 版本控制
  version INTEGER DEFAULT 1,
  parent_document_id UUID REFERENCES documents(id),

  -- 处理状态
  processing_status TEXT DEFAULT 'pending' CHECK (
    processing_status IN ('pending', 'processing', 'completed', 'failed', 'archived')
  ),
  processing_started_at TIMESTAMPTZ,
  processing_completed_at TIMESTAMPTZ,
  error_details JSONB,

  -- 统计信息
  chunk_count INTEGER DEFAULT 0,
  total_tokens INTEGER DEFAULT 0,

  -- 元数据
  metadata JSONB DEFAULT '{}',
  tags TEXT[] DEFAULT '{}',

  -- 审计字段
  uploaded_by UUID REFERENCES auth.users(id),
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),

  -- 索引
  CONSTRAINT unique_content_hash_per_project UNIQUE(project_id, content_hash)
);

-- 文档访问日志（可选，用于分析）
CREATE TABLE document_access_logs (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
  user_id UUID REFERENCES auth.users(id) ON DELETE SET NULL,

  access_type TEXT NOT NULL CHECK (access_type IN ('view', 'search', 'download')),
  accessed_at TIMESTAMPTZ DEFAULT NOW(),

  -- 分区键
  log_date DATE GENERATED ALWAYS AS (DATE(accessed_at)) STORED
) PARTITION BY RANGE (log_date);

-- 为日志表创建月度分区
CREATE TABLE document_access_logs_y2024m01 PARTITION OF document_access_logs
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

#### 1.3、对话与消息系统
```sql
-- 对话表：支持多模态和复杂交互
CREATE TABLE conversations (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  org_id UUID REFERENCES organizations(id) ON DELETE CASCADE,
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,

  -- 对话元信息
  title TEXT,
  description TEXT,

  -- AI 配置
  system_prompt TEXT,
  model_config JSONB DEFAULT '{}', -- 模型参数、温度等
  context_window INTEGER DEFAULT 4000, -- 上下文窗口大小

  -- 状态管理
  status TEXT DEFAULT 'active' CHECK (status IN ('active', 'archived', 'deleted')),
  is_shared BOOLEAN DEFAULT FALSE, -- 是否共享给团队

  -- 统计信息
  message_count INTEGER DEFAULT 0,
  total_input_tokens INTEGER DEFAULT 0,
  total_output_tokens INTEGER DEFAULT 0,
  total_cost DECIMAL(10,6) DEFAULT 0,

  -- 关联信息
  parent_conversation_id UUID REFERENCES conversations(id), -- 支持对话分支
  tags TEXT[] DEFAULT '{}',

  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 消息表：支持多模态内容和复杂状态
CREATE TABLE messages (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  conversation_id UUID REFERENCES conversations(id) ON DELETE CASCADE,

  -- 消息基本信息
  role TEXT NOT NULL CHECK (role IN ('system', 'user', 'assistant', 'tool')),
  content TEXT NOT NULL,
  content_type TEXT DEFAULT 'text' CHECK (content_type IN ('text', 'image', 'audio', 'file', 'multimodal')),

  -- 多模态支持
  attachments JSONB DEFAULT '[]', -- 附件列表：图片、文件等

  -- 流式状态
  status TEXT DEFAULT 'completed' CHECK (status IN ('pending', 'streaming', 'completed', 'failed', 'cancelled')),
  stream_position INTEGER DEFAULT 0,

  -- AI 元数据
  model_name TEXT,
  model_version TEXT,
  token_count INTEGER,
  finish_reason TEXT, -- 'stop', 'length', 'content_filter'

  -- 工具调用支持
  tool_calls JSONB, -- OpenAI 格式的工具调用
  tool_call_id TEXT, -- 工具调用的响应 ID

  -- 引用与上下文
  parent_message_id UUID REFERENCES messages(id), -- 支持消息回复
  references JSONB DEFAULT '[]', -- 引用的文档、代码片段等
  context_sources JSONB DEFAULT '[]', -- RAG 检索的来源

  -- 质量评估
  rating INTEGER CHECK (rating BETWEEN 1 AND 5),
  feedback TEXT,
  flagged BOOLEAN DEFAULT FALSE,
  flag_reason TEXT,

  -- 成本追踪
  input_cost DECIMAL(10,6) DEFAULT 0,
  output_cost DECIMAL(10,6) DEFAULT 0,

  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 消息编辑历史（可选）
CREATE TABLE message_edit_history (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  message_id UUID REFERENCES messages(id) ON DELETE CASCADE,

  previous_content TEXT NOT NULL,
  edit_type TEXT CHECK (edit_type IN ('user_edit', 'regenerate', 'system_update')),
  edited_by UUID REFERENCES auth.users(id),

  created_at TIMESTAMPTZ DEFAULT NOW()
);
```

### 2、索引策略与性能优化

#### 2.1、关键业务索引
```sql
-- 租户隔离查询优化
CREATE INDEX idx_documents_org_project_status ON documents(org_id, project_id, processing_status);
CREATE INDEX idx_conversations_user_updated ON conversations(user_id, updated_at DESC);
CREATE INDEX idx_messages_conversation_created ON messages(conversation_id, created_at);

-- 向量检索优化
CREATE INDEX idx_embeddings_vector_cosine ON embeddings
USING ivfflat (vector vector_cosine_ops) WITH (lists = 100);

-- 全文搜索支持
CREATE INDEX idx_documents_content_fts ON documents
USING gin(to_tsvector('english', title || ' ' || COALESCE(content, '')));

-- 用量查询优化
CREATE INDEX idx_usage_events_org_time ON usage_events(org_id, created_at DESC);
CREATE INDEX idx_usage_events_user_time ON usage_events(user_id, created_at DESC);

-- 复合索引：多维度查询
CREATE INDEX idx_documents_project_tags ON documents USING gin(project_id, tags);
CREATE INDEX idx_conversations_shared_active ON conversations(is_shared, status) WHERE status = 'active';
```

#### 2.2、分区表策略
```sql
-- 按时间分区的大表
-- 用量事件按月分区
CREATE TABLE usage_events (
  -- ... 列定义
  created_at TIMESTAMPTZ DEFAULT NOW()
) PARTITION BY RANGE (created_at);

-- 创建分区函数
CREATE OR REPLACE FUNCTION create_monthly_partition(
  table_name TEXT,
  start_date DATE
) RETURNS VOID AS $$
DECLARE
  partition_name TEXT;
  end_date DATE;
BEGIN
  end_date := start_date + INTERVAL '1 month';
  partition_name := table_name || '_y' || EXTRACT(YEAR FROM start_date) || 'm' || LPAD(EXTRACT(MONTH FROM start_date)::TEXT, 2, '0');

  EXECUTE format('CREATE TABLE IF NOT EXISTS %I PARTITION OF %I FOR VALUES FROM (%L) TO (%L)',
    partition_name, table_name, start_date, end_date);
END;
$$ LANGUAGE plpgsql;

-- 自动创建未来 6 个月的分区
DO $$
DECLARE
  current_month DATE := DATE_TRUNC('month', NOW());
  i INTEGER;
BEGIN
  FOR i IN 0..5 LOOP
    PERFORM create_monthly_partition('usage_events', current_month + (i * INTERVAL '1 month'));
  END LOOP;
END $$;
```

### 3、数据完整性与约束

#### 3.1、业务规则约束
```sql
-- 向量维度一致性检查
ALTER TABLE embeddings ADD CONSTRAINT check_vector_dimension
CHECK (array_length(vector, 1) = 1536);

-- 用量事件数据有效性
ALTER TABLE usage_events ADD CONSTRAINT check_positive_tokens
CHECK (input_tokens >= 0 AND output_tokens >= 0);

ALTER TABLE usage_events ADD CONSTRAINT check_positive_cost
CHECK (input_cost >= 0 AND output_cost >= 0);

-- 消息顺序约束
CREATE UNIQUE INDEX idx_messages_conversation_created_unique
ON messages(conversation_id, created_at);

-- 组织 slug 格式约束
ALTER TABLE organizations ADD CONSTRAINT check_slug_format
CHECK (slug ~ '^[a-z0-9][a-z0-9-]*[a-z0-9]$' AND length(slug) BETWEEN 3 AND 63);
```

#### 3.2、级联删除策略
```sql
-- 软删除支持
ALTER TABLE documents ADD COLUMN deleted_at TIMESTAMPTZ;
ALTER TABLE conversations ADD COLUMN deleted_at TIMESTAMPTZ;

-- 创建软删除视图
CREATE VIEW active_documents AS
SELECT * FROM documents WHERE deleted_at IS NULL;

CREATE VIEW active_conversations AS
SELECT * FROM conversations WHERE deleted_at IS NULL AND status != 'deleted';

-- 级联归档函数
CREATE OR REPLACE FUNCTION archive_project_data(p_project_id UUID)
RETURNS VOID AS $$
BEGIN
  -- 归档文档
  UPDATE documents SET processing_status = 'archived'
  WHERE project_id = p_project_id AND processing_status != 'failed';

  -- 归档对话
  UPDATE conversations SET status = 'archived'
  WHERE project_id = p_project_id AND status = 'active';

  -- 记录归档事件
  INSERT INTO audit_logs (event_type, resource_type, resource_id, details)
  VALUES ('archive', 'project', p_project_id, jsonb_build_object('archived_at', NOW()));
END;
$$ LANGUAGE plpgsql;
```

### 4、扩展性设计模式

#### 4.1、JSONB 灵活字段
```sql
-- 元数据字段的标准化结构
-- documents.metadata 字段示例：
{
  "source": "upload|api|sync",
  "language": "en|zh|auto",
  "processing_options": {
    "chunk_size": 1000,
    "overlap": 200,
    "extract_tables": true
  },
  "quality_metrics": {
    "readability_score": 0.8,
    "content_type": "technical|marketing|legal"
  },
  "custom_fields": {
    "department": "engineering",
    "confidentiality": "internal"
  }
}

-- 为 JSONB 字段创建 GIN 索引
CREATE INDEX idx_documents_metadata ON documents USING gin(metadata);

-- JSONB 查询示例
-- 查找特定部门的文档
SELECT * FROM documents
WHERE metadata->>'department' = 'engineering';

-- 查找包含特定处理选项的文档
SELECT * FROM documents
WHERE metadata @> '{"processing_options": {"extract_tables": true}}';
```

#### 4.2、扩展表模式
```sql
-- 为不同类型的文档创建扩展表
CREATE TABLE document_extensions (
  document_id UUID REFERENCES documents(id) ON DELETE CASCADE PRIMARY KEY,
  extension_type TEXT NOT NULL, -- 'code', 'legal', 'medical'
  extension_data JSONB NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 代码文档扩展
-- extension_data 示例：
{
  "language": "python",
  "framework": "django",
  "complexity_score": 0.7,
  "dependencies": ["requests", "pandas"],
  "functions": [
    {"name": "process_data", "line_start": 10, "line_end": 50}
  ]
}

-- 法律文档扩展
{
  "document_type": "contract",
  "jurisdiction": "california",
  "parties": ["company_a", "company_b"],
  "clauses": [
    {"type": "confidentiality", "section": "5.1"}
  ]
}
```

这个数据模型设计提供了：
- **可扩展性**：通过 JSONB 和扩展表支持灵活的业务需求
- **高性能**：合理的索引策略和分区设计
- **数据完整性**：完善的约束和级联规则
- **多租户安全**：严格的租户隔离和权限控制

## 十、安全与合规

AI 应用处理的数据往往包含敏感信息，从个人对话记录到企业机密文档，安全与合规不仅是技术要求，更是业务生存的基础。Supabase 的多层安全机制为构建合规的 AI 应用提供了坚实保障。

### 1、多层次 RLS 安全策略

#### 1.1、组织级基础隔离
确保不同组织的数据完全隔离，防止任何形式的数据泄露：

```sql
-- 基础组织隔离策略模板
CREATE OR REPLACE FUNCTION create_org_isolation_policy(
  table_name TEXT,
  org_column TEXT DEFAULT 'org_id'
) RETURNS VOID AS $$
BEGIN
  EXECUTE format('
    CREATE POLICY "%s_org_isolation" ON %I
    FOR ALL USING (
      %I = ANY(
        SELECT org_id FROM memberships
        WHERE user_id = auth.uid()
        AND status = ''active''
      )
    )', table_name, table_name, org_column);
END;
$$ LANGUAGE plpgsql;

-- 应用到所有业务表
SELECT create_org_isolation_policy('documents');
SELECT create_org_isolation_policy('conversations');
SELECT create_org_isolation_policy('usage_events');
```

#### 1.2、项目级细粒度控制
在组织内部按项目进行更细致的权限管理：

```sql
-- 项目级访问控制策略
CREATE POLICY "project_based_access" ON documents
FOR ALL USING (
  -- 组织成员身份验证
  EXISTS (
    SELECT 1 FROM memberships m
    WHERE m.user_id = auth.uid()
    AND m.org_id = documents.org_id
    AND m.status = 'active'
  )
  AND
  -- 项目权限验证
  (
    -- 组织管理员可访问所有项目
    EXISTS (
      SELECT 1 FROM memberships m
      WHERE m.user_id = auth.uid()
      AND m.org_id = documents.org_id
      AND m.role IN ('owner', 'admin')
    )
    OR
    -- 项目成员访问权限
    EXISTS (
      SELECT 1 FROM project_memberships pm
      WHERE pm.user_id = auth.uid()
      AND pm.project_id = documents.project_id
      AND pm.permission_level IN ('read', 'write', 'admin')
    )
  )
);
```

#### 1.3、资源级权限控制
对特定资源实施更精细的访问控制：

```sql
-- 文档级权限控制
CREATE TABLE document_permissions (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
  document_id UUID REFERENCES documents(id) ON DELETE CASCADE,
  user_id UUID REFERENCES auth.users(id) ON DELETE CASCADE,

  permission_type TEXT NOT NULL CHECK (permission_type IN ('read', 'write', 'admin')),
  granted_by UUID REFERENCES auth.users(id),
  expires_at TIMESTAMPTZ,

  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- 文档级 RLS 策略
CREATE POLICY "document_level_permissions" ON documents
FOR SELECT USING (
  -- 基础项目权限 OR 特定文档权限
  (
    EXISTS (
      SELECT 1 FROM project_memberships pm
      WHERE pm.user_id = auth.uid()
      AND pm.project_id = documents.project_id
    )
  )
  OR
  (
    EXISTS (
      SELECT 1 FROM document_permissions dp
      WHERE dp.document_id = documents.id
      AND dp.user_id = auth.uid()
      AND dp.permission_type IN ('read', 'write', 'admin')
      AND (dp.expires_at IS NULL OR dp.expires_at > NOW())
    )
  )
);
```

### 2、敏感数据保护（PII 管理）

#### 2.1、数据分类与标记
```sql
-- 数据敏感度分类表
CREATE TABLE data_classifications (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,

  resource_type TEXT NOT NULL, -- 'document', 'conversation', 'message'
  resource_id UUID NOT NULL,

  classification_level TEXT NOT NULL CHECK (
    classification_level IN ('public', 'internal', 'confidential', 'restricted')
  ),

  pii_types TEXT[] DEFAULT '{}', -- ['email', 'phone', 'ssn', 'credit_card']
  compliance_requirements TEXT[] DEFAULT '{}', -- ['gdpr', 'hipaa', 'pci']

  classified_by UUID REFERENCES auth.users(id),
  classification_reason TEXT,

  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 自动 PII 检测函数
CREATE OR REPLACE FUNCTION detect_pii_in_content(content TEXT)
RETURNS TEXT[] AS $$
DECLARE
  pii_types TEXT[] := '{}';
BEGIN
  -- 邮箱检测
  IF content ~* '\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b' THEN
    pii_types := array_append(pii_types, 'email');
  END IF;

  -- 电话号码检测
  IF content ~* '\b\d{3}[-.]?\d{3}[-.]?\d{4}\b' THEN
    pii_types := array_append(pii_types, 'phone');
  END IF;

  -- 信用卡号检测（简化版）
  IF content ~* '\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b' THEN
    pii_types := array_append(pii_types, 'credit_card');
  END IF;

  RETURN pii_types;
END;
$$ LANGUAGE plpgsql;

-- 自动分类触发器
CREATE OR REPLACE FUNCTION auto_classify_content()
RETURNS TRIGGER AS $$
DECLARE
  detected_pii TEXT[];
  classification TEXT := 'internal';
BEGIN
  -- 检测 PII
  detected_pii := detect_pii_in_content(NEW.content);

  -- 根据 PII 类型确定分类级别
  IF array_length(detected_pii, 1) > 0 THEN
    classification := 'confidential';
  END IF;

  -- 插入或更新分类
  INSERT INTO data_classifications (
    resource_type, resource_id, classification_level, pii_types, classified_by
  ) VALUES (
    TG_TABLE_NAME, NEW.id, classification, detected_pii, auth.uid()
  ) ON CONFLICT (resource_type, resource_id) DO UPDATE SET
    classification_level = EXCLUDED.classification_level,
    pii_types = EXCLUDED.pii_types,
    updated_at = NOW();

  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- 为相关表添加触发器
CREATE TRIGGER auto_classify_documents
  AFTER INSERT OR UPDATE OF content ON documents
  FOR EACH ROW EXECUTE FUNCTION auto_classify_content();

CREATE TRIGGER auto_classify_messages
  AFTER INSERT OR UPDATE OF content ON messages
  FOR EACH ROW EXECUTE FUNCTION auto_classify_content();
```

#### 2.2、数据脱敏与掩码
```sql
-- 数据脱敏函数
CREATE OR REPLACE FUNCTION mask_sensitive_data(
  content TEXT,
  mask_level TEXT DEFAULT 'partial'
) RETURNS TEXT AS $$
BEGIN
  CASE mask_level
    WHEN 'full' THEN
      -- 完全掩码：用 [REDACTED] 替换
      RETURN regexp_replace(content, '\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '[EMAIL_REDACTED]', 'g');
    WHEN 'partial' THEN
      -- 部分掩码：保留部分字符
      RETURN regexp_replace(content, '\b([A-Za-z0-9._%+-]+)@([A-Za-z0-9.-]+\.[A-Z|a-z]{2,})\b', '\1***@***.\2', 'g');
    ELSE
      RETURN content;
  END CASE;
END;
$$ LANGUAGE plpgsql;

-- 基于角色的内容视图
CREATE VIEW documents_masked AS
SELECT
  d.*,
  CASE
    WHEN dc.classification_level IN ('confidential', 'restricted')
         AND NOT check_user_role(d.org_id, 'admin') THEN
      mask_sensitive_data(d.content, 'partial')
    ELSE d.content
  END as content_masked
FROM documents d
LEFT JOIN data_classifications dc ON dc.resource_type = 'documents' AND dc.resource_id = d.id;
```

### 3、审计与日志记录

#### 3.1、全面审计日志
```sql
-- 审计日志表
CREATE TABLE audit_logs (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,

  -- 事件信息
  event_type TEXT NOT NULL, -- 'create', 'read', 'update', 'delete', 'access'
  event_subtype TEXT, -- 'document_view', 'message_send', 'search_query'

  -- 资源信息
  resource_type TEXT NOT NULL, -- 'document', 'conversation', 'user'
  resource_id UUID,

  -- 用户信息
  user_id UUID REFERENCES auth.users(id) ON DELETE SET NULL,
  user_email TEXT,
  user_ip INET,
  user_agent TEXT,

  -- 会话信息
  session_id TEXT,
  org_id UUID REFERENCES organizations(id) ON DELETE SET NULL,
  project_id UUID REFERENCES projects(id) ON DELETE SET NULL,

  -- 事件详情
  details JSONB DEFAULT '{}',

  -- 安全相关
  risk_level TEXT DEFAULT 'low' CHECK (risk_level IN ('low', 'medium', 'high', 'critical')),
  flagged BOOLEAN DEFAULT FALSE,

  created_at TIMESTAMPTZ DEFAULT NOW(),

  -- 分区键
  log_date DATE GENERATED ALWAYS AS (DATE(created_at)) STORED
) PARTITION BY RANGE (log_date);

-- 审计触发器函数
CREATE OR REPLACE FUNCTION log_audit_event()
RETURNS TRIGGER AS $$
DECLARE
  user_info RECORD;
  risk_level TEXT := 'low';
BEGIN
  -- 获取用户信息
  SELECT email INTO user_info FROM auth.users WHERE id = auth.uid();

  -- 评估风险级别
  IF TG_OP = 'DELETE' THEN
    risk_level := 'medium';
  ELSIF TG_TABLE_NAME IN ('documents', 'conversations') AND TG_OP = 'UPDATE' THEN
    risk_level := 'medium';
  END IF;

  -- 记录审计日志
  INSERT INTO audit_logs (
    event_type, resource_type, resource_id, user_id, user_email,
    org_id, details, risk_level
  ) VALUES (
    lower(TG_OP), TG_TABLE_NAME,
    COALESCE(NEW.id, OLD.id),
    auth.uid(), user_info.email,
    COALESCE(NEW.org_id, OLD.org_id),
    jsonb_build_object(
      'table', TG_TABLE_NAME,
      'operation', TG_OP,
      'changed_columns',
      CASE WHEN TG_OP = 'UPDATE' THEN
        (SELECT array_agg(key) FROM jsonb_each(to_jsonb(NEW)) WHERE value != to_jsonb(OLD) -> key)
      ELSE NULL END
    ),
    risk_level
  );

  RETURN COALESCE(NEW, OLD);
END;
$$ LANGUAGE plpgsql;

-- 为关键表添加审计触发器
CREATE TRIGGER audit_documents
  AFTER INSERT OR UPDATE OR DELETE ON documents
  FOR EACH ROW EXECUTE FUNCTION log_audit_event();

CREATE TRIGGER audit_conversations
  AFTER INSERT OR UPDATE OR DELETE ON conversations
  FOR EACH ROW EXECUTE FUNCTION log_audit_event();
```

#### 3.2、API 访问日志
```sql
-- API 访问日志表
CREATE TABLE api_access_logs (
  id UUID DEFAULT gen_random_uuid() PRIMARY KEY,

  -- 请求信息
  request_id TEXT UNIQUE,
  method TEXT NOT NULL,
  path TEXT NOT NULL,
  query_params JSONB,

  -- 认证信息
  user_id UUID REFERENCES auth.users(id) ON DELETE SET NULL,
  api_key_id UUID REFERENCES api_keys(id) ON DELETE SET NULL,
  auth_method TEXT CHECK (auth_method IN ('jwt', 'api_key', 'anonymous')),

  -- 网络信息
  client_ip INET,
  user_agent TEXT,
  referer TEXT,

  -- 响应信息
  status_code INTEGER,
  response_time_ms INTEGER,
  response_size BIGINT,

  -- 业务信息
  org_id UUID REFERENCES organizations(id) ON DELETE SET NULL,
  project_id UUID REFERENCES projects(id) ON DELETE SET NULL,

  -- 安全标记
  is_suspicious BOOLEAN DEFAULT FALSE,
  rate_limited BOOLEAN DEFAULT FALSE,

  created_at TIMESTAMPTZ DEFAULT NOW()
) PARTITION BY RANGE (created_at);

-- Edge Functions 中的日志记录
-- 在每个 Edge Function 中添加：
export async function logApiAccess(request: Request, response: Response, metadata: any) {
  const startTime = Date.now();

  const logData = {
    request_id: crypto.randomUUID(),
    method: request.method,
    path: new URL(request.url).pathname,
    query_params: Object.fromEntries(new URL(request.url).searchParams),
    client_ip: request.headers.get('x-forwarded-for'),
    user_agent: request.headers.get('user-agent'),
    status_code: response.status,
    response_time_ms: Date.now() - startTime,
    org_id: metadata.orgId,
    project_id: metadata.projectId
  };

  await supabase
    .from('api_access_logs')
    .insert(logData);
}
```

### 4、合规框架支持

#### 4.1、GDPR 合规
```sql
-- GDPR 用户权利支持
-- 数据可携带性：导出用户所有数据
CREATE OR REPLACE FUNCTION export_user_data(p_user_id UUID)
RETURNS JSONB AS $$
DECLARE
  user_data JSONB := '{}';
BEGIN
  -- 基础用户信息
  SELECT jsonb_build_object(
    'profile', to_jsonb(up.*),
    'memberships', (
      SELECT jsonb_agg(to_jsonb(m.*)) FROM memberships m WHERE m.user_id = p_user_id
    ),
    'conversations', (
      SELECT jsonb_agg(to_jsonb(c.*)) FROM conversations c WHERE c.user_id = p_user_id
    ),
    'messages', (
      SELECT jsonb_agg(to_jsonb(msg.*))
      FROM messages msg
      JOIN conversations c ON msg.conversation_id = c.id
      WHERE c.user_id = p_user_id
    ),
    'documents', (
      SELECT jsonb_agg(to_jsonb(d.*)) FROM documents d WHERE d.uploaded_by = p_user_id
    )
  ) INTO user_data
  FROM user_profiles up WHERE up.id = p_user_id;

  RETURN user_data;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- 被遗忘权：安全删除用户数据
CREATE OR REPLACE FUNCTION forget_user(p_user_id UUID)
RETURNS VOID AS $$
BEGIN
  -- 软删除用户内容（保留审计需要）
  UPDATE conversations SET
    user_id = NULL,
    title = '[USER_DELETED]',
    updated_at = NOW()
  WHERE user_id = p_user_id;

  UPDATE messages SET
    content = '[CONTENT_DELETED]',
    updated_at = NOW()
  WHERE conversation_id IN (
    SELECT id FROM conversations WHERE user_id = p_user_id
  );

  -- 匿名化审计日志
  UPDATE audit_logs SET
    user_email = '[DELETED]',
    details = details || '{"user_forgotten": true}'
  WHERE user_id = p_user_id;

  -- 删除个人资料
  DELETE FROM user_profiles WHERE id = p_user_id;
  DELETE FROM memberships WHERE user_id = p_user_id;

  -- 记录删除操作
  INSERT INTO audit_logs (
    event_type, resource_type, resource_id, details
  ) VALUES (
    'gdpr_forget', 'user', p_user_id,
    jsonb_build_object('forgotten_at', NOW(), 'reason', 'gdpr_request')
  );
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
```

#### 4.2、SOC 2 Type II 合规
```sql
-- 访问控制审计
CREATE VIEW access_control_audit AS
SELECT
  u.email as user_email,
  o.name as organization,
  m.role as org_role,
  p.name as project,
  pm.permission_level as project_permission,
  m.created_at as access_granted_at,
  m.status
FROM memberships m
JOIN auth.users u ON m.user_id = u.id
JOIN organizations o ON m.org_id = o.id
LEFT JOIN project_memberships pm ON pm.user_id = m.user_id
LEFT JOIN projects p ON pm.project_id = p.id
WHERE m.status = 'active'
ORDER BY o.name, u.email;

-- 异常访问检测
CREATE OR REPLACE FUNCTION detect_suspicious_activity()
RETURNS TABLE (
  user_id UUID,
  user_email TEXT,
  suspicious_activity TEXT,
  risk_score INTEGER
) AS $$
BEGIN
  RETURN QUERY
  WITH user_activity AS (
    SELECT
      al.user_id,
      al.user_email,
      COUNT(*) as activity_count,
      COUNT(DISTINCT al.user_ip) as ip_count,
      COUNT(*) FILTER (WHERE al.event_type = 'delete') as delete_count,
      COUNT(*) FILTER (WHERE al.created_at > NOW() - INTERVAL '1 hour') as recent_activity
    FROM audit_logs al
    WHERE al.created_at > NOW() - INTERVAL '24 hours'
    GROUP BY al.user_id, al.user_email
  )
  SELECT
    ua.user_id,
    ua.user_email,
    CASE
      WHEN ua.ip_count > 5 THEN 'Multiple IP addresses'
      WHEN ua.delete_count > 10 THEN 'Excessive deletions'
      WHEN ua.recent_activity > 100 THEN 'High frequency activity'
      ELSE 'Unknown'
    END as suspicious_activity,
    CASE
      WHEN ua.ip_count > 5 THEN 3
      WHEN ua.delete_count > 10 THEN 4
      WHEN ua.recent_activity > 100 THEN 2
      ELSE 1
    END as risk_score
  FROM user_activity ua
  WHERE ua.ip_count > 5 OR ua.delete_count > 10 OR ua.recent_activity > 100;
END;
$$ LANGUAGE plpgsql;
```

### 5、密钥管理与轮换

#### 5.1、API 密钥安全管理
```sql
-- 密钥轮换函数
CREATE OR REPLACE FUNCTION rotate_api_key(p_key_id UUID)
RETURNS TEXT AS $$
DECLARE
  new_key TEXT;
  new_key_hash TEXT;
BEGIN
  -- 生成新密钥
  new_key := 'sk_' || encode(gen_random_bytes(32), 'hex');
  new_key_hash := encode(digest(new_key, 'sha256'), 'hex');

  -- 更新密钥记录
  UPDATE api_keys SET
    key_hash = new_key_hash,
    updated_at = NOW(),
    last_rotated_at = NOW()
  WHERE id = p_key_id;

  -- 记录轮换事件
  INSERT INTO audit_logs (
    event_type, resource_type, resource_id, details
  ) VALUES (
    'key_rotation', 'api_key', p_key_id,
    jsonb_build_object('rotated_at', NOW())
  );

  RETURN new_key;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- 自动密钥轮换（定期任务）
CREATE OR REPLACE FUNCTION auto_rotate_expired_keys()
RETURNS INTEGER AS $$
DECLARE
  rotated_count INTEGER := 0;
  key_record RECORD;
BEGIN
  FOR key_record IN
    SELECT id FROM api_keys
    WHERE last_rotated_at < NOW() - INTERVAL '90 days'
    OR created_at < NOW() - INTERVAL '90 days'
  LOOP
    PERFORM rotate_api_key(key_record.id);
    rotated_count := rotated_count + 1;
  END LOOP;

  RETURN rotated_count;
END;
$$ LANGUAGE plpgsql;
```

#### 5.2、加密数据存储
```sql
-- 敏感数据加密扩展
CREATE EXTENSION IF NOT EXISTS pgcrypto;

-- 敏感字段加密
CREATE TABLE encrypted_user_data (
  user_id UUID REFERENCES auth.users(id) PRIMARY KEY,
  encrypted_data TEXT, -- PGP 加密的敏感数据
  encryption_key_id TEXT,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- 加密/解密函数
CREATE OR REPLACE FUNCTION encrypt_sensitive_data(
  data TEXT,
  encryption_key TEXT
) RETURNS TEXT AS $$
BEGIN
  RETURN pgp_sym_encrypt(data, encryption_key);
END;
$$ LANGUAGE plpgsql;

CREATE OR REPLACE FUNCTION decrypt_sensitive_data(
  encrypted_data TEXT,
  encryption_key TEXT
) RETURNS TEXT AS $$
BEGIN
  RETURN pgp_sym_decrypt(encrypted_data, encryption_key);
EXCEPTION
  WHEN OTHERS THEN
    RETURN NULL; -- 解密失败返回 NULL
END;
$$ LANGUAGE plpgsql;
```

这套安全与合规框架提供了：
- **纵深防御**：多层次的权限控制和数据保护
- **合规支持**：GDPR、SOC 2 等主流合规框架的技术实现
- **实时监控**：全面的审计日志和异常检测
- **数据保护**：PII 检测、数据脱敏和加密存储

## 十一、工程化与运维

AI 应用的生命周期管理需要特殊考虑：模型版本变更、向量索引重建、用量突增等都对运维提出了更高要求。基于 Supabase 的工程化实践需要在敏捷开发与稳定运行之间找到平衡。

### 1、环境分层与配置管理

**多环境架构**：
- **本地环境**：完整功能的本地 Supabase 实例，支持离线开发
- **预发环境**：与生产环境配置一致的测试环境
- **生产环境**：高可用配置，完整监控和备份策略

**配置管理最佳实践**：
- 使用环境变量管理不同环境的配置
- 密钥通过专用的密钥管理服务注入
- 数据库连接串、API Key 等敏感信息不写入代码

### 2、数据库迁移与种子数据

**迁移策略**：
- 使用 Supabase CLI 管理数据库 schema 变更
- 每个迁移都包含前向和回滚脚本
- 大型数据迁移分批执行，避免长时间锁表

**种子数据管理**：
- 开发环境使用模拟数据，便于功能测试
- 预发环境使用脱敏的生产数据，保证测试真实性
- 生产环境的初始数据通过专门的种子脚本管理

### 3、监控与观测

**关键监控指标**：
- **数据库性能**：慢查询、连接池使用率、锁等待时间
- **向量检索质量**：召回率、检索延迟、索引命中率
- **AI 服务可用性**：API 响应时间、错误率、token 消耗速率
- **用户体验指标**：页面加载时间、对话响应速度、功能可用性

**日志管理**：
- 结构化日志输出，便于自动化分析
- 错误日志实时告警，关键业务异常立即通知
- 审计日志长期保存，满足合规要求

## 十二、性能与成本优化

### 1、数据库性能优化

**连接管理**：
- 使用连接池避免频繁建立连接的开销
- 合理配置连接超时时间，防止连接泄露
- 读写分离：只读查询使用只读副本，减少主库压力

**索引策略**：
- 为高频查询字段建立合适的索引
- 定期分析索引使用情况，清理无效索引
- 向量索引参数根据数据规模动态调整

**查询优化**：
- 避免 N+1 查询问题，使用合适的关联查询
- 大结果集分页处理，避免一次性加载过多数据
- 复杂聚合查询使用物化视图预计算

### 2、向量检索性能

**索引选择策略**：
- 数据量 < 10万：使用 `ivfflat` 索引，查询速度快
- 数据量 > 10万：使用 `hnsw` 索引，内存效率高
- 定期重建索引，保持最优性能

**查询优化**：
- 合理设置相似度阈值，平衡召回率和精确度
- 使用混合检索（向量 + 关键词），提升检索效果
- 缓存热门查询结果，减少重复计算

### 3、成本控制策略

**存储成本优化**：
- 冷热数据分层：历史对话归档到低成本存储
- 数据生命周期管理：定期清理过期数据
- 压缩策略：文档内容和向量数据使用合适的压缩算法

**计算成本控制**：
- AI 推理成本预算管理，防止异常消耗
- 缓存策略减少重复的 AI 调用
- 合理的请求限流，避免恶意使用

## 十三、选型对比分析

### 1、vs Firebase

| 维度 | Supabase | Firebase |
|------|----------|----------|
| **数据库** | PostgreSQL，支持复杂查询 | NoSQL，简单查询友好 |
| **向量支持** | 原生 pgvector 支持 | 需要外部向量数据库 |
| **权限控制** | RLS 行级安全 | Security Rules |
| **自托管** | 完全开源，可自托管 | 仅云服务 |
| **学习曲线** | 需要 SQL 基础 | 相对简单 |
| **AI 集成** | 一体化解决方案 | 需要多个服务集成 |

### 2、何时选择其他方案

**选择传统技术栈的场景**：
- 团队有丰富的微服务架构经验
- 需要极度定制化的业务逻辑
- 对特定技术栈有强依赖

**选择专用向量数据库的场景**：
- 向量数据规模超过 1000万条
- 需要特殊的向量算法支持
- 对检索延迟有极高要求（< 10ms）

## 十四、实战路线图

### 1、阶段一：MVP 验证（2-4 周）

**目标**：快速验证核心功能，获得用户反馈

**关键里程碑**：
- **Week 1-2**：基础架构搭建
  - Supabase 项目初始化
  - 用户认证系统
  - 基础数据模型设计
- **Week 3-4**：核心功能实现
  - 文档上传与向量化
  - 简单的问答功能
  - 基础的用户界面

**验收标准**：
- [ ] 用户可以注册登录
- [ ] 可以上传文档并进行基础问答
- [ ] 多租户数据隔离正常工作
- [ ] 基础的错误处理和用户反馈

### 2、阶段二：产品化（4-6 周）

**目标**：完善功能，提升用户体验，准备商业化

**关键里程碑**：
- **Week 1-2**：高级功能开发
  - 流式对话实现
  - 对话历史管理
  - 高级权限控制
- **Week 3-4**：性能优化
  - 向量检索优化
  - 数据库性能调优
  - 缓存策略实现
- **Week 5-6**：商业化准备
  - 用量统计与计费
  - 配额管理
  - 订阅系统

**验收标准**：
- [ ] 流式对话体验流畅
- [ ] 检索性能满足用户期望
- [ ] 完整的计费和配额系统
- [ ] 用户可以自助管理账户

### 3、阶段三：规模化（6-8 周）

**目标**：支持大规模用户，完善运维体系

**关键里程碑**：
- **Week 1-3**：扩展性改进
  - 数据库分区策略
  - 读写分离实现
  - 缓存层架构
- **Week 4-5**：安全与合规
  - 审计日志完善
  - 数据加密和脱敏
  - 合规性检查
- **Week 6-8**：运维自动化
  - CI/CD 流水线
  - 监控告警系统
  - 自动化测试

**验收标准**：
- [ ] 支持 10万+ 并发用户
- [ ] 完整的监控和告警体系
- [ ] 自动化部署和回滚
- [ ] 通过安全合规审计

## 十五、结语与扩展阅读

在 AI 编程时代，**Supabase** 为构建智能应用提供了一个独特的价值主张：它不仅仅是一个数据库，而是一个完整的后端生态系统，特别适合需要快速迭代和验证想法的 AI 应用场景。

### 1、核心价值总结

1. **开发效率**：显著缩短从想法到产品的开发周期
2. **AI 原生**：向量检索和权限控制的完美结合
3. **企业就绪**：内置的安全和合规能力
4. **成本可控**：从免费开始，按需扩展

### 2、技术趋势展望

- **向量数据库普及**：未来每个应用都需要语义搜索能力
- **边缘 AI 计算**：推理能力向边缘节点下沉
- **多模态融合**：文本、图像、音频的统一处理
- **AI 安全**：专门针对 AI 应用的安全防护

### 3、扩展阅读

**官方资源**：
- [Supabase 官方文档](https://supabase.com/docs)
- [pgvector 使用指南](https://github.com/pgvector/pgvector)
- [Edge Functions 开发指南](https://supabase.com/docs/guides/functions)

**技术深度**：
- 《PostgreSQL 向量检索性能优化实战》
- 《Row Level Security 企业级权限设计》
- 《AI 应用成本优化完全指南》

**社区资源**：
- Supabase Discord 社区
- GitHub Discussions 技术讨论
- 定期的开发者 Office Hours

无论你是独立开发者还是企业团队，重要的是先动手实践，在实际项目中感受 Supabase 的强大功能。AI 编程时代才刚刚开始，让我们一起构建更智能的应用！

**祝你变得更强!**
