
## 为何学习 Elasticsearch

Elasticsearch 是一款开源的、分布式的、实时的搜索与数据分析引擎，它具有高度的可伸缩性、灵活性和实时性，能够帮助用户在大量数据中进行高效的搜索、分析和数据挖掘。在当今这个信息爆炸的时代，学习 Elasticsearch 成为了一项重要的技能，原因如下：

1. **高性能搜索**：Elasticsearch 基于 Apache Lucene 构建，提供了全文搜索、模糊匹配和多语言支持等功能，使得用户可以在海量数据中快速找到相关信息。

2. **实时数据分析**：Elasticsearch 支持实时的数据分析和聚合，用户可以在短时间内对大量数据进行处理，以获得有价值的洞察和业务智能。

3. **分布式与可伸缩性**：Elasticsearch 具有分布式架构，能够在多台服务器上横向扩展，轻松应对不断增长的数据量和查询负载。

4. **丰富的生态系统**：Elasticsearch 是 ELK（Elasticsearch、Logstash 和 Kibana）技术栈的核心组件，结合其他组件可以实现日志分析、监控、数据可视化等多种场景。

5. **广泛的应用领域**：Elasticsearch 在各种领域都有广泛的应用，如电商、金融、医疗、教育等，学习 Elasticsearch 有助于提高在这些领域的工作技能。

<!-- more -->

## 发展历史

Elasticsearch 的发展历程如下：

- **2004年**：Doug Cutting 和 Mike Cafarella 开始开发 Apache Lucene，一款开源的全文搜索引擎库，后来成为 Elasticsearch 的基础技术。

- **2010年**：Shay Banon 创立 Elasticsearch 项目，以解决分布式环境下的搜索和分析问题。他的启发源自于他为家人开发的食谱搜索应用。

- **2012年**：Elasticsearch 成立公司，开始提供商业支持和服务。

- **2013年**：公司推出 Logstash 和 Kibana，与 Elasticsearch 配合使用，形成了 ELK 技术栈。

- **2015年**：Elasticsearch 公司正式更名为 Elastic，继续扩展其产品线，包括 Beats、Elastic Cloud 等。

- **2018年**：Elastic 在纳斯达克上市，股票代码为 "ESTC"。

从诞生至今，Elasticsearch 已经成为全球最受欢迎的搜索与分析引擎之一，并得到了众多知名企业和开发者的

## 基础概念
### 集群

集群是由多个 Elasticsearch 节点组成的一个完整的系统，这些节点共同工作以提供分布式搜索和数据分析功能。集群具有以下特点：

1. **高可用性**：集群中的节点可以相互协作，当某个节点出现故障时，其他节点会接管其工作，确保系统的正常运行。

2. **数据分布**：集群可以将数据分布在多个节点上，实现数据的负载均衡和性能优化。

3. **水平扩展**：当集群需要处理更多的数据和查询时，可以通过添加节点来提高集群的处理能力。

### 节点

节点是 Elasticsearch 集群中的一个独立的服务器，负责处理数据和执行搜索、分析任务。节点有以下类型：

1. **主节点**：负责管理集群的元数据，如索引的创建、删除、映射配置等。一个集群只能有一个主节点。

2. **数据节点**：负责存储数据和执行数据相关的操作，如搜索、分析、聚合等。

3. **协调节点**：负责分发客户端的请求到各个数据节点，并汇总、返回结果。

4. **摄取节点**：负责预处理数据，如数据转换、过滤等，然后将处理后的数据传递给数据节点。

### 分片

分片是 Elasticsearch 的一个核心概念，它可以将一个大的索引拆分成多个较小的、独立的部分。分片有以下优点：

1. **水平扩展**：通过增加分片数量，可以在更多节点上分布数据，提高查询和写入的性能。

2. **容错性**：当某个分片所在的节点出现故障时，其他节点上的分片仍然可以提供服务。

3. **并行处理**：分片可以让多个节点同时处理数据，提高查询和分析的速度。

### 副本

副本是分片的一个备份，它可以提高数据的可用性和容错性。副本有以下作用：

1. **容错性**：当一个分片所在的节点发生故障时，副本可以替代原始分片继续提供服务。

2. **负载均衡**：副本可以在多个节点上分布，提供搜索和读取的负载均衡。

3. **高可用性**：副本可以确保在节点故障或网络分区等异常情况下，数据仍然可以被访问。

在设计 Elasticsearch 集群时，需要根据实际需求和场景来合理配置分片和副本的数量，以达到最佳的性能和可靠性。

### 索引

在 Elasticsearch 中，索引是一个用于存储和检索文档的逻辑空间。它类似于传统数据库中的表，是组织和管理数据的基本单位。索引具有以下特点：

1. **映射**：索引定义了数据的结构和类型，称为映射。映射包括字段名、数据类型、分析器等属性，可以帮助 Elasticsearch 更高效地处理和查询数据。

2. **分片与副本**：索引由多个分片组成，每个分片可以有一个或多个副本。分片和副本可以在集群的多个节点上分布，提高查询和写入的性能，以及数据的可用性和容错性。

3. **动态索引**：Elasticsearch 支持动态创建索引和映射，当接收到新的文档时，可以根据预定义的规则自动创建对应的索引和映射。

4. **别名**：为了方便管理和查询，可以为索引设置别名。使用别名可以让你在不改变查询逻辑的情况下，轻松地对索引进行重建或者迁移。

### 文档

文档是 Elasticsearch 中存储和处理的基本数据单位，它代表了一个具体的实体或对象。文档具有以下特点：

1. **JSON 格式**：文档使用 JSON 格式表示，这是一种轻量级、易于阅读和编写的数据交换格式。JSON 格式使得文档可以包含复杂的数据结构，如数组、嵌套对象等。

2. **唯一标识**：每个文档都有一个唯一的标识，称为 `_id`。你可以在创建文档时自定义 `_id`，或者让 Elasticsearch 自动生成。

3. **元数据**：除了用户定义的数据之外，文档还包含一些元数据，如 `_index`（所属索引）、`_type`（文档类型，已经在 Elasticsearch 7.x 中废弃）和 `_version`（文档版本）等。

4. **全文搜索**：Elasticsearch 可以对文档的内容进行全文搜索、模糊匹配和多语言支持等功能，使得用户可以在大量数据中快速找到相关信息。

在 Elasticsearch 中，你可以执行各种操作来创建、更新、删除和查询文档，如使用 RESTful API、Java 客户端或者其他语言的客户端库。同时，Elasticsearch 还提供了一系列高级功能，如排序、过滤、聚合和地理位置搜索等，帮助你更有效地处理和分析数据。

在 Elasticsearch 中，setting 和 mapping 是用于定义和配置索引结构的两个重要概念。

### 倒排索引
Elasticsearch使用倒排索引（Inverted Index）来快速查询文档。倒排索引是一个数据结构，它存储了每个术语（Term）在哪些文档中出现过。对于一个查询语句，Elasticsearch会在倒排索引中寻找关键词所在的文档，然后对这些文档进行计算，得出符合查询条件的结果。

倒排索引的构建过程主要包括以下两个步骤：

分词（Tokenization）：将文档中的字符串切分成一个个单词或术语。这里的单词或术语是指被定义了的一些基本单位，例如英文字母或数字等。

建立词条表（Term Dictionary）：对于文档中的每个术语，建立一张该术语出现的文档列表。这样就可以查找包含某个词语的文档。

在倒排索引中，术语是一个基本单位，也称为Term。每个Term都有一个Document Frequency（DF），即该术语出现在的文档数。此外，每个Term在每个文档中可能会出现多次，为了存储更多信息，索引还会维护一个Positions List，用于记录Term在文档中的位置信息。

倒排索引使得Elasticsearch能够以较小的代价（O(1)级别）查找包含某个术语的文档列表。倒排索引也允许Elasticsearch支持高效的全文搜索、短语搜索等复杂查询。可以说，倒排索引是Elasticsearch的核心特性之一，也是其高效检索的关键所在。


### Setting

Setting 是用于配置索引参数和行为的设置。它包括了诸如分片数量、副本数量、分词器配置等方面的内容。Setting 可以在创建索引时进行配置，也可以在索引创建后进行部分修改。以下是一些常见的 setting 配置：

1. **分片数量**：设置索引的主分片数量，这个值在索引创建后不能修改。例如：`"number_of_shards": 5`。

2. **副本数量**：设置每个分片的副本数量，这个值在索引创建后可以修改。例如：`"number_of_replicas": 1`。

3. **分词器配置**：配置自定义分词器、分词过滤器等，以支持特定语言或业务场景的文本分析。例如，可以定义一个用于处理英文文本的自定义分词器。

通过设置合适的 setting 参数，可以根据具体应用场景和需求对索引进行优化，以提高查询性能和数据可用性。

### Mapping

Mapping 是用于定义索引中文档的字段结构和属性的映射。它相当于传统关系型数据库中的表结构定义。Mapping 包括字段名、字段类型、分析器等信息。以下是一些常见的 mapping 配置：

1. **字段类型**：指定字段的数据类型，如字符串、整数、日期等。例如：`"title": { "type": "text" }`。

2. **字段分析器**：指定字段的分析器，用于处理全文搜索的文本分割和分析。例如：`"description": { "type": "text", "analyzer": "english" }`。

3. **嵌套对象**：定义嵌套的对象结构，以支持更复杂的数据模型。例如，一个文档可以包含一个作者对象，该对象包含姓名和电子邮件等属性。

4. **多字段**：可以为同一个字段定义多个子字段，以支持不同的查询和分析需求。例如，一个字段可以同时支持全文搜索和精确匹配。

Mapping 的配置对于 Elasticsearch 的查询性能和搜索结果准确性至关重要。一个合适的 mapping 设置可以提高查询效率，减少误匹配和无关结果。

### 示例
以下是一个使用 REST API 创建 Elasticsearch 索引的示例，其中包括了 setting 和 mapping 的设置。在本例中，我们创建一个名为 "blog" 的索引。

```
PUT /blog
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 1,
    "analysis": {
      "analyzer": {
        "my_custom_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "asciifolding"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "analyzer": "my_custom_analyzer"
      },
      "content": {
        "type": "text",
        "analyzer": "my_custom_analyzer"
      },
      "publish_date": {
        "type": "date"
      },
      "tags": {
        "type": "keyword"
      },
      "author": {
        "properties": {
          "name": {
            "type": "text"
          },
          "email": {
            "type": "keyword"
          }
        }
      }
    }
  }
}
```

在这个例子中：

1. 在 `settings` 部分，我们设置了索引的分片数（`number_of_shards`）为 1，副本数（`number_of_replicas`）为 1。我们还自定义了一个名为 "my_custom_analyzer" 的分析器，它使用标准分词器（`standard`）和两个过滤器：小写过滤器（`lowercase`）和 ASCII 折叠过滤器（`asciifolding`）。

2. 在 `mappings` 部分，我们定义了文档的字段结构和类型。包括：`title`（文本类型，使用自定义分析器）、`content`（文本类型，使用自定义分析器）、`publish_date`（日期类型）、`tags`（关键词类型）以及一个嵌套的 `author` 对象（包含 `name` 和 `email` 字段）。

通过这个示例，你可以看到如何使用 REST API 来设置 Elasticsearch 索引的 setting 和 mapping。

示例中setting包含了分片和副本数，上面章节已经有基本介绍。还用到分析器，后面内容会讲到。

## 文档的CURD

1. **创建（Create）**：向 "blog" 索引中添加一篇博客文章：

```
POST /blog/_doc/
{
  "title": "Elasticsearch: Getting Started",
  "content": "This is a beginner's guide to Elasticsearch.",
  "publish_date": "2023-04-25T12:00:00Z",
  "tags": ["Elasticsearch", "Guide"],
  "author": {
    "name": "John Doe",
    "email": "john.doe@example.com"
  }
}
```

2. **读取（Read）**：获取刚刚创建的博客文章。假设文章的 `_id` 为 `1`：

```
GET /blog/_doc/1
```

3. **更新（Update）**：更新博客文章的部分内容。在这个例子中，我们为文章添加一个新的标签：

```
POST /blog/_doc/1/_update
{
  "doc": {
    "tags": ["Elasticsearch", "Guide", "Tutorial"]
  }
}
```

另外，你还可以使用脚本来更新文档的内容：

```
POST /blog/_doc/1/_update
{
  "script": {
    "source": "ctx._source.tags.add(params.new_tag)",
    "params": {
      "new_tag": "Search"
    }
  }
}
```

4. **删除（Delete）**：删除博客文章。假设文章的 `_id` 为 `1`：

```
DELETE /blog/_doc/1
```

## Analyzer
在 Elasticsearch 中，Analyzer（分析器）是用于处理全文搜索中的文本分析过程的组件。文本分析是将文本数据转换成可以被倒排索引存储和查询的词项的过程。

分析器通常由三个部分组成：
- 分词器（Tokenizer）：分词器将文本拆分成独立的词项。例如，标准分词器会将文本按空格和标点符号拆分成单词。
- 分词过滤器（Token Filter）：分词过滤器对从分词器产生的词项进行处理和过滤。常见的分词过滤器包括小写过滤器（将词项转换为小写）、停用词过滤器（去除常见的停用词，如 "and"、"the" 等）和词干提取过滤器（将词项转换为其词干，以便在搜索时匹配不同形式的单词）。
- 字符过滤器（Char Filter）：字符过滤器对原始文本进行预处理，例如删除 HTML 标签、转换特殊字符等。

Elasticsearch 提供了许多内置的分析器：
1. `Standard Analyzer` 标准分析器是Elasticsearch中最常用的分析器之一，它会将文本按照标点符号、空格等进行分词，同时会将文本转换为小写字母。Standard Analyzer适用于一般性的全文搜索场景，可以快速地进行分词和检索。
2. `Simple Analyzer` 简单分析器是一种比标准分析器更加简单的分析器，它只会将文本按照空格进行分词，并且不会进行任何转换操作。Simple Analyzer适用于不需要考虑大小写和单复数等问题的场景，比如数字、代码等。
3. `Whitespace Analyzer` 空格分析器会将文本按照空格进行分词，不会进行任何转换操作。Whitespace Analyzer适用于不需要进行复杂分词和处理的场景，比如标签、ID等。
4. `Keyword Analyzer` 关键字分析器会将整个文本作为一个关键字进行索引，不会进行任何分词和处理操作。Keyword Analyzer适用于需要精确匹配的场景，比如产品编号、邮编等。
5. `Stop Analyzer` 停用词分析器会去除文本中的停用词，如“and”、“the”等，然后再进行分词和转换操作。Stop Analyzer适用于需要排除常用词语的场景，比如文章标题、关键字等。
6. `Pattern Analyzer` 模式分析器会按照正则表达式对文本进行分词和转换操作，可以根据需要进行自定义。Pattern Analyzer适用于需要自定义分词规则的场景，比如特殊字符、中文词语等。
7. `Language Analyzer` 语言分析器会根据文本所属的语言进行分词和转换操作，可以提高分析的准确性和效率。Elasticsearch中支持多种语言的分析器，如中文、英文、法文等。

### 字符过滤器 使用

###  分词过滤器 使用

###  分词器 使用

### 中文分词

### 拼音分词



