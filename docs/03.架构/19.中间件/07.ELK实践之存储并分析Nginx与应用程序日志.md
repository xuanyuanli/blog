

mkdir -p /etc/logstash/pipeline/

docker run --name logstash -d --net=host -v /etc/logstash/pipeline/:/usr/share/logstash/pipeline/ docker.elastic.co/logstash/logstash:7.3.1
```editorconfig
input {
  tcp {
    port => 5055
    codec => json_lines
  }
}
output {
    elasticsearch {
        hosts => [ "es-cn.elasticsearch.com:9200" ]
        user => "elastic"
        password => "elastic"
        index => "logstash-%{[input][type]}-%{[fields][input_type_source]}-%{+YYYY.MM.dd}"
    }
}
```
```editorconfig
input {
    beats {
        port => "5044"
    }
}
filter {
    // 使用正则表达式模式匹配来解析日志中的字段。匹配到的字段会被添加到事件中，并从事件中移除原始的message字段。
    grok {
        match => { "message" => "%{IPORHOST:remote_addr} - %{DATA:remote_user} \[%{HTTPDATE:time_local}\] \"%{NUMBER:request_time}\" \"%{NUMBER:upstream_response_time}\" \"%{DATA:host}\" \"%{DATA:request_uri}\" %{NUMBER:status} %{NUMBER:body_bytes_sent} \"%{DATA:http_referer}\" \"%{DATA:http_user_agent}\" \"%{WORD:request_method}\" \"%{GREEDYDATA:request_body}\""}
        remove_field => "message"
    }
    // 用于添加和转换字段
    mutate {
        // 添加自定义字段，这里是添加了一个字段，值为@timestamp
        add_field => { "read_timestamp" => "%{@timestamp}" }
        convert => {
            "request_time" => "float"
            "upstream_response_time" => "float"
            "status" => "integer"
            "body_bytes_sent" => "integer"
        }
    }
    // 用于解析http_user_agent字段，获取用户代理信息
    useragent {
        source => "http_user_agent"
        target => "nginx_http_user_agent"
        remove_field => "http_user_agent"
    }
    // 会把time_local字段的值转换为@timestamp的值
    date {
        match => [ "time_local", "dd/MMM/YYYY:H:m:s Z" ]
        remove_field => "time_local"
    }
    // 用于通过客户端IP地址获取地理位置信息
    geoip {
        source => "remote_addr"
    }
}
output {
    elasticsearch {
        hosts => [ "es-cn.elasticsearch.com:9200" ]
        user => "elastic"
        password => "elastic"
        index => "logstash-%{[input][type]}-%{[fields][input_type_source]}-%{+YYYY.MM.dd}"
    }
}
```

```editorconfig
    log_format main escape=json '$remote_addr - $remote_user [$time_local] "$request_time" "$upstream_response_time" "$host" "$request_uri" '
    '$status $body_bytes_sent "$http_referer" '
    '"$http_user_agent" "$request_method" "$request_body" ';
```

```text
59.110.219.226 -  [29/May/2023:17:30:35 +0800] "0.002" "0.002" "m.x.cn" "/apis/test?Id=29493" 200 8 "https://m.x.cn/auction/live/29493?s=11f231ff" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/99.0.4844.51 Safari/537.36" "GET" "" 
42.80.163.166 -  [29/May/2023:17:30:35 +0800] "0.002" "0.002" "m.x.cn" "/apis/live/test?Id=29567" 200 8 "https://m.x.cn/auction/live/29567?s=5a9ac8c2" "Mozilla/5.0 (iPhone; CPU iPhone OS 15_7_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148" "GET" "" 
45.153.128.19 -  [29/May/2023:17:37:52 +0800] "0.000" "0.000" "m.x.cn" "/apis/code" 403 37 "" "LangShen" "POST" "{\"mobile\":\"13700000000\",\"zoneCode\":\"86\"}" 
```

docker run -d --name filebeat-nginx --net=host -v /usr/local/nginx/:/usr/local/nginx/ -v /etc/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml docker.elastic.co/beats/filebeat:7.3.1 filebeat -e  -d "publish"
```yaml
filebeat.inputs:
- type: log
  paths:
    - /usr/local/nginx/logs/access.log  
  fields:
     input_type_source: nginx
output.logstash:
  hosts: ["172.28.0.1:5044"]
```

要将Logback的日志输出发送到Logstash，可以通过使用Logstash的Logback插件来实现。以下是配置步骤：

1. 在项目的依赖管理中添加Logstash Logback插件的依赖。示例中使用Maven：

```xml
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
    <version>6.6</version>
</dependency>
```

2. 在Logback的配置文件中进行相应的配置，以将日志输出发送给Logstash。示例配置如下：

```xml
<configuration>
    <appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>your-logstash-host:your-logstash-port</destination>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
    </appender>
    
    <root level="INFO">
        <appender-ref ref="LOGSTASH" />
    </root>
</configuration>
```

在配置中，`your-logstash-host`和`your-logstash-port`需要替换为实际的Logstash主机和端口。

3. 配置Logstash接收和处理Logback日志事件。在Logstash的配置文件中，可以使用`tcp`或`udp`输入插件来接收来自Logback的日志事件，并使用其他输出插件（如Elasticsearch、File等）进行日志的存储或进一步处理。

示例Logstash配置如下：

```conf
input {
  tcp {
    port => your-logstash-port
    codec => json_lines
  }
}

output {
  elasticsearch {
    hosts => ["your-elasticsearch-host:9200"]
    index => "your-index-name"
  }
}
```

在上述配置中，`your-logstash-port`需要与Logback配置中的端口保持一致，`your-elasticsearch-host`是你的Elasticsearch主机，`your-index-name`是你希望将日志存储到的Elasticsearch索引名称。

4. 确保Logback和Logstash之间的网络连接可用，并启动Logstash和你的应用程序。Logback将会将日志事件发送到Logstash，并根据Logstash配置进行相应的处理和存储。

通过以上步骤，你可以将Logback的日志输出发送给Logstash，并进一步处理、存储或分析日志数据。请根据你的实际环境和需求进行相应的配置调整。

https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html  grok语法
https://grokconstructor.appspot.com/do/match 验证
https://blog.51cto.com/u_13527416/2117141 演示了kafka作为中间件，数据缓冲队列，具有峰值处理能力，使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。

Kibana：
- 创建 index templates
- 创建 index lifecycle policy
- 关联 index templates 和 index lifecycle policy

- 创建Index patterns
- 在Discover处进行查询

https://balagetech.com/visualizing-nginx-access-logs-kibana/  创建Dashboard
